var documenterSearchIndex = {"docs":
[{"location":"cuda/#CUDA-Acceleration","page":"CUDA","title":"CUDA Acceleration","text":"OMEinsum supports GPU acceleration through CUDA.jl. By uploading your data to the GPU, you can significantly accelerate tensor contractions.","category":"section"},{"location":"cuda/#Basic-CUDA-Usage","page":"CUDA","title":"Basic CUDA Usage","text":"julia> using CUDA, OMEinsum\n\njulia> code = ein\"ij,jk,kl,li->\"  # the einsum notation\nij, jk, kl, li -> \n\njulia> A, B, C, D = rand(1000, 1000), rand(1000, 300), rand(300, 800), rand(800, 1000);\n\njulia> size_dict = OMEinsum.get_size_dict(getixsv(code), (A, B, C, D))  # get the size of the labels\nDict{Char, Int64} with 4 entries:\n  'j' => 1000\n  'i' => 1000\n  'k' => 300\n  'l' => 800\n\njulia> optcode = optimize_code(code, size_dict, TreeSA())  # optimize the contraction order\nSlicedEinsum{Char, DynamicNestedEinsum{Char}}(Char[], kl, kl -> \n├─ ki, li -> kl\n│  ├─ jk, ij -> ki\n│  │  ├─ jk\n│  │  └─ ij\n│  └─ li\n└─ kl\n)\n\nThe contraction order is optimized. Now, let's benchmark the contraction on the CPU.\n\njulia> using BenchmarkTools\n\njulia> @btime optcode($A, $B, $C, $D)  # the contraction on CPU\n  6.053 ms (308 allocations: 20.16 MiB)\n0-dimensional Array{Float64, 0}:\n1.4984046443610943e10\n\nThe contraction on the CPU takes about 6 ms. Now, let's upload the data to the GPU and perform the contraction on the GPU.\n\njulia> cuA, cuB, cuC, cuD = CuArray(A), CuArray(B), CuArray(C), CuArray(D);\n\njulia> @btime CUDA.@sync optcode($cuA, $cuB, $cuC, $cuD)  # the contraction on GPU\n  243.888 μs (763 allocations: 28.56 KiB)\n0-dimensional CuArray{Float64, 0, CUDA.DeviceMemory}:\n1.4984046443610939e10","category":"section"},{"location":"cuda/#GPU-Backends","page":"CUDA","title":"GPU Backends","text":"OMEinsum provides two backends for GPU tensor contractions:\n\nBackend Library Best For\nDefaultBackend() CUBLAS Matrix-like contractions (GEMM patterns)\nCuTensorBackend() cuTENSOR General tensor contractions","category":"section"},{"location":"cuda/#DefaultBackend-(CUBLAS)","page":"CUDA","title":"DefaultBackend (CUBLAS)","text":"The default backend uses NVIDIA's CUBLAS library. It works by:\n\nAnalyzing the contraction pattern\nReshaping tensors to fit matrix multiplication (GEMM) format\nCalling CUBLAS.gemm_strided_batched!\nReshaping the result back\n\nThis approach works well for contractions that naturally map to matrix multiplication, such as:\n\nein\"ij,jk->ik\" (matrix multiplication)\nein\"ijl,jkl->ikl\" (batched matrix multiplication)","category":"section"},{"location":"cuda/#CuTensorBackend-(cuTENSOR)","page":"CUDA","title":"CuTensorBackend (cuTENSOR)","text":"The cuTENSOR backend uses NVIDIA's cuTENSOR library, which provides native tensor contraction without the reshape/permute overhead. This is especially beneficial for:\n\nNon-GEMM patterns: Contractions like ein\"ijk,jkl->il\" that don't naturally fit GEMM\nHigh-dimensional tensors: Avoids costly permutations\nComplex index patterns: Direct support for arbitrary contraction patterns","category":"section"},{"location":"cuda/#Using-the-cuTENSOR-Backend","page":"CUDA","title":"Using the cuTENSOR Backend","text":"","category":"section"},{"location":"cuda/#Prerequisites","page":"CUDA","title":"Prerequisites","text":"cuTENSOR requires:\n\nNVIDIA GPU with compute capability ≥ 6.0\nCUDA.jl v5.0 or later\ncuTENSOR.jl package (install with Pkg.add(\"cuTENSOR\"))","category":"section"},{"location":"cuda/#Check-Availability","page":"CUDA","title":"Check Availability","text":"using CUDA\nusing cuTENSOR  # Must be loaded to enable the cuTENSOR backend\nusing OMEinsum\n\n# Check if cuTENSOR is available\nif cuTENSOR.has_cutensor()\n    println(\"cuTENSOR is available!\")\nelse\n    println(\"cuTENSOR is not available\")\nend\n\nimportant: Loading cuTENSOR\ncuTENSOR.jl is a separate package. You must:Install it: Pkg.add(\"cuTENSOR\")\nLoad it before or alongside OMEinsum: using cuTENSORThis triggers OMEinsum's CuTENSORExt extension, which provides the cuTENSOR backend functionality.","category":"section"},{"location":"cuda/#Enable-cuTENSOR-Backend","page":"CUDA","title":"Enable cuTENSOR Backend","text":"using CUDA\nusing cuTENSOR  # ← Required! This loads the CuTENSORExt extension\nusing OMEinsum\n\n# Set the backend globally\nset_einsum_backend!(CuTensorBackend())\n\n# Now all GPU einsum operations will use cuTENSOR\nA = CUDA.rand(Float32, 100, 200, 300)\nB = CUDA.rand(Float32, 200, 300, 400)\nC = ein\"ijk,jkl->il\"(A, B)  # Uses cuTENSOR\n\n# Reset to default backend\nset_einsum_backend!(DefaultBackend())\n\nwarning: Forgetting to load cuTENSOR\nIf you set CuTensorBackend() without loading cuTENSOR.jl, you'll see:┌ Warning: CuTensorBackend: cuTENSOR.jl not loaded - run `using cuTENSOR` first. Will fall back to CUBLAS.The computation will still work (using CUBLAS), but you won't get the cuTENSOR optimization.","category":"section"},{"location":"cuda/#Supported-Data-Types","page":"CUDA","title":"Supported Data Types","text":"The cuTENSOR backend supports BLAS-compatible types:\n\nFloat16, Float32, Float64\nComplexF16, ComplexF32, ComplexF64\n\nFor other types (e.g., Double64, custom number types), the cuTENSOR backend automatically falls back to the DefaultBackend (CUBLAS-based) implementation.","category":"section"},{"location":"cuda/#Example:-Performance-Comparison","page":"CUDA","title":"Example: Performance Comparison","text":"using CUDA\nusing cuTENSOR  # Required for cuTENSOR backend\nusing OMEinsum, BenchmarkTools\n\n# Create test tensors (non-GEMM pattern)\nA = CUDA.rand(Float32, 64, 64, 64)\nB = CUDA.rand(Float32, 64, 64, 64)\n\n# Benchmark with DefaultBackend (CUBLAS)\nset_einsum_backend!(DefaultBackend())\n@btime CUDA.@sync ein\"ijk,jkl->il\"($A, $B)\n# Requires: permute → reshape → GEMM → reshape\n\n# Benchmark with CuTensorBackend\nset_einsum_backend!(CuTensorBackend())\n@btime CUDA.@sync ein\"ijk,jkl->il\"($A, $B)\n# Direct tensor contraction - no intermediate steps!","category":"section"},{"location":"cuda/#When-to-Use-cuTENSOR","page":"CUDA","title":"When to Use cuTENSOR","text":"Use Case Recommended Backend\nMatrix multiplication ij,jk->ik Either (similar performance)\nBatched matmul ijl,jkl->ikl Either (similar performance)\nTensor contraction ijk,jkl->il CuTensorBackend\nHigh-dimensional ijkl,klmn->ijmn CuTensorBackend\nMPS/PEPS contractions CuTensorBackend\nNon-BLAS types (Double64, etc.) DefaultBackend","category":"section"},{"location":"cuda/#Best-Practices","page":"CUDA","title":"Best Practices","text":"Use cuTENSOR for tensor networks: If you're doing MPS, PEPS, or general tensor network contractions, cuTENSOR typically provides better performance.\nProfile your workload: The relative performance depends on tensor sizes and contraction patterns. Use BenchmarkTools to measure.\nKeep data on GPU: Minimize CPU-GPU transfers by keeping intermediate results on the GPU.\nBatch operations: When contracting many small tensors, consider batching them together.\n\n# Good: Keep data on GPU throughout\ncuA, cuB, cuC = CuArray.((A, B, C))\nresult = ein\"(ij,jk),kl->il\"(cuA, cuB, cuC)\n\n# Avoid: Repeated transfers\nresult = ein\"ij,jk->ik\"(CuArray(A), CuArray(B))  # Transfer every call","category":"section"},{"location":"cuda/#Nested-Contractions-with-cuTENSOR","page":"CUDA","title":"Nested Contractions with cuTENSOR","text":"The cuTENSOR backend works seamlessly with optimized contraction orders:\n\nusing CUDA, cuTENSOR, OMEinsum\n\nset_einsum_backend!(CuTensorBackend())\n\n# Define a tensor network\ncode = ein\"ij,jk,kl,lm->im\"\n\n# Optimize contraction order\nsize_dict = Dict('i'=>100, 'j'=>100, 'k'=>100, 'l'=>100, 'm'=>100)\noptcode = optimize_code(code, size_dict, TreeSA())\n\n# Execute with cuTENSOR (each pairwise contraction uses cuTENSOR)\nA, B, C, D = [CUDA.rand(Float32, 100, 100) for _ in 1:4]\nresult = optcode(A, B, C, D)","category":"section"},{"location":"cuda/#Troubleshooting","page":"CUDA","title":"Troubleshooting","text":"","category":"section"},{"location":"cuda/#cuTENSOR-not-detected","page":"CUDA","title":"cuTENSOR not detected","text":"If has_cutensor() returns false:\n\nCheck CUDA.jl version: Ensure you have CUDA.jl v5.0+\nusing Pkg\nPkg.status(\"CUDA\")\nCheck GPU compatibility: cuTENSOR requires compute capability ≥ 6.0\nusing CUDA\nCUDA.capability(CUDA.device())\nReinstall CUDA artifacts:\nusing CUDA\nCUDA.versioninfo()  # Check if cuTENSOR is listed","category":"section"},{"location":"cuda/#Performance-not-as-expected","page":"CUDA","title":"Performance not as expected","text":"Ensure synchronization: Use CUDA.@sync when benchmarking\nCheck tensor sizes: cuTENSOR has more overhead for very small tensors\nVerify backend is active: Check get_einsum_backend()","category":"section"},{"location":"cuda/#Video-Tutorial","page":"CUDA","title":"Video Tutorial","text":"To learn more about using GPU and autodiff, please check out the following asciinema video. (Image: asciicast)","category":"section"},{"location":"contractionorder/#Contraction-order-optimization","page":"Contraction order optimization","title":"Contraction order optimization","text":"","category":"section"},{"location":"contractionorder/#Constructing-a-code","page":"Contraction order optimization","title":"Constructing a code","text":"The @ein_str string literal does not optimize the contraction order for more than two input tensors. We first use a graph to construct a DynamicEinCode object for demonstration.\n\nusing OMEinsum, OMEinsumContractionOrders, OMEinsumContractionOrders.Graphs\n\ngraph = random_regular_graph(20, 3; seed=42)\n\ncode = EinCode([[e.src, e.dst] for e in edges(graph)], Int[])\n\nThe return value is a StaticEinCode object that does not contain a contraction order. The time and space complexity can be obtained by calling the contraction_complexity function.\n\nsize_dict = uniformsize(code, 2)  # size of the labels are set to 2\n\ncontraction_complexity(code, size_dict)  # time and space complexity\n\nThe return values are log2 values of the number of iterations, number of elements of the largest tensor and the number of elementwise read-write operations.","category":"section"},{"location":"contractionorder/#Optimizing-the-contraction-order","page":"Contraction order optimization","title":"Optimizing the contraction order","text":"To optimize the contraction order, we can use the optimize_code function.\n\noptcode = optimize_code(code, size_dict, TreeSA(ntrials=1))\n\nThe output value is a binary contraction tree with type SlicedEinsum or NestedEinsum. The TreeSA is a local search algorithm that optimizes the contraction order. More algorithms can be found in the OMEinsumContractionOrders documentation.\n\nAfter optimizing the contraction order, the time and readwrite complexities are significantly reduced.\n\ncontraction_complexity(optcode, size_dict)","category":"section"},{"location":"contractionorder/#Slicing-the-code","page":"Contraction order optimization","title":"Slicing the code","text":"In some cases, the memory usage of the contraction is too large. Slicing is a technique to reduce the time and space complexity of the contraction. The slicing is done by using the slice_code function.\n\nslicer = TreeSASlicer(score=ScoreFunction(sc_target=2))\nscode = slice_code(optcode, size_dict, slicer);\ncontraction_complexity(scode, size_dict)\nscode.slicing\n\nThe return value is a SlicedEinsum object. The space complexity is reduced to 2, while the time complexity is increased as a trade-off.","category":"section"},{"location":"contractionorder/#Using-optein-string-literal","page":"Contraction order optimization","title":"Using optein string literal","text":"For convenience, the optimized contraction can be directly contructed by using the @optein_str string literal.\n\noptein\"ij,jk,kl,li->\"  # optimized contraction, without knowing the size of the tensors\n\n@optein_str optimizes the contraction order with the assumption that each index has the same size 2, hence the resulting contraction order might not be optimal.","category":"section"},{"location":"contractionorder/#Manual-optimization","page":"Contraction order optimization","title":"Manual optimization","text":"One can also manually specify the contraction order by using the @ein_str string literal.\n\nein\"((ij,jk),kl),li->ik\"  # manually optimized contraction","category":"section"},{"location":"contractionorder/#Flatten-the-code","page":"Contraction order optimization","title":"Flatten the code","text":"Given an optimized code, one can flatten it to get a code without contraction order with type EinCode.\n\nOMEinsum.flatten(optcode)","category":"section"},{"location":"applications/#Application","page":"Applications","title":"Application","text":"","category":"section"},{"location":"applications/#List-of-packages-using-OMEinsum","page":"Applications","title":"List of packages using OMEinsum","text":"GenericTensorNetworks, solving combinational optimization problems by generic tensor networks.\nTensorInference, probabilistic inference using contraction of tensor networks\nYaoToEinsum, the tensor network simulation backend for quantum circuits.\nTensorNetworkAD2, using differential programming tensor networks to solve quantum many-body problems.\nTensorQEC, tensor networks for quantum error correction.","category":"section"},{"location":"applications/#Example:-Solving-a-3-coloring-problem-on-the-Petersen-graph","page":"Applications","title":"Example: Solving a 3-coloring problem on the Petersen graph","text":"Let us focus on graphs with vertices with three edges each. A question one might ask is: How many different ways are there to colour the edges of the graph with three different colours such that no vertex has a duplicate colour on its edges?\n\nThe counting problem can be transformed into a contraction of rank-3 tensors representing the edges. Consider the tensor s defined as\n\nusing OMEinsum\ns = map(x->Int(length(unique(x.I)) == 3), CartesianIndices((3,3,3)))\n\nThen we can simply contract s tensors to get the number of 3 colourings satisfying the above condition! E.g. for two vertices, we get 6 distinct colourings:\n\nein\"ijk,ijk->\"(s,s)[]\n\nUsing that method, it's easy to find that e.g. the peterson graph allows no 3 colouring, since\n\ncode = ein\"afl,bhn,cjf,dlh,enj,ago,big,cki,dmk,eom->\"\nafl, bhn, cjf, dlh, enj, ago, big, cki, dmk, eom \ncode(fill(s, 10)...)[]\n\nThe peterson graph consists of 10 vertices and 15 edges and looks like a pentagram embedded in a pentagon as depicted here:\n\n(Image: )\n\nOMEinsum does not optimie the contraction order by default, so the above contraction can be time consuming. To speed up the contraction, we can use optimize_code to optimize the contraction order:\n\noptcode = optimize_code(code, uniformsize(code, 3), TreeSA())\ncontraction_complexity(optcode, uniformsize(optcode, 3))\noptcode(fill(s, 10)...)[]\n\nWe can see the time complexity of the optimized code is much smaller than the original one. To know more about the contraction order optimization, please check the Julia package OMEinsumContractionOrders.jl.\n\nConfronted with the above result, we can ask whether the peterson graph allows a relaxed variation of 3 colouring, having one vertex that might accept duplicate colours. The answer to that can be found using the gradient w.r.t a vertex:\n\nusing Zygote: gradient\ngradient(x->optcode(x,s,s,s,s,s,s,s,s,s)[], s)[1] |> sum\n\nThis tells us that even if we allow duplicates on one vertex, there are no 3-colourings for the peterson graph.","category":"section"},{"location":"basic/#Basic-Usage","page":"Basic usage","title":"Basic Usage","text":"In the following example, we demonstrate the einsum notation for basic tensor operations.","category":"section"},{"location":"basic/#Einsum-notation","page":"Basic usage","title":"Einsum notation","text":"To specify the operation, the user can either use the @ein_str-string literal or the EinCode object. For example, both the following code snippets define the matrix multiplication operation:\n\nusing OMEinsum\ncode1 = ein\"ij,jk -> ik\"  # the string literal\nixs = [[1, 2], [2, 3]]  # the input indices\niy = [1, 3]  # the output indices\ncode2 = EinCode(ixs, iy)  # the EinCode object (equivalent to the string literal)\n\nThe @ein_str macro can be used to define the einsum notation directly in the function call.\n\nA, B = randn(2, 3), randn(3, 4);\ncode1(A, B)  # matrix multiplication\nsize_dict = OMEinsum.get_size_dict(getixsv(code1), (A, B))  # get the size of the labels\neinsum(code1, (A, B), size_dict)  # lower-level function\neinsum!(code1, (A, B), zeros(2, 4), true, false, size_dict)  # the in-place operation\n@ein C[i,k] := A[i,j] * B[j,k]  # all-in-one macro\n\nHere, we show that the @ein macro combines the einsum notation defintion and the operation in a single line, which is more convenient for simple operations. Separating the einsum notation and the operation (the first approach) can be useful for reusing the einsum notation for multiple input tensors. Lower level functions, einsum and einsum!, can be used for more control over the operation.\n\nFor more than two input tensors, the @ein_str macro does not optimize the contraction order. In such cases, the user can use the @optein_str string literal to optimize the contraction order or specify the contraction order manually.\n\ntensors = [randn(100, 100) for _ in 1:4];\noptein\"ij,jk,kl,lm->im\"(tensors...)  # optimized contraction (without knowing the size)\nein\"(ij,jk),(kl,lm)->im\"(tensors...)  # manually specified contraction\n\nSometimes, manually optimizing the contraction order can be beneficial. Please check Contraction order optimization for more details.","category":"section"},{"location":"basic/#Einsum-examples","page":"Basic usage","title":"Einsum examples","text":"We first define the tensors and then demonstrate the einsum notation for various tensor operations.\n\nusing OMEinsum\ns = fill(1)  # scalar\nw, v = [1, 2], [4, 5];  # vectors\nA, B = [1 2; 3 4], [5 6; 7 8]; # matrices\nT1, T2 = reshape(1:8, 2, 2, 2), reshape(9:16, 2, 2, 2); # 3D tensor","category":"section"},{"location":"basic/#Unary-examples","page":"Basic usage","title":"Unary examples","text":"ein\"i->\"(w)  # sum of the elements of a vector.\nein\"ij->i\"(A)  # sum of the rows of a matrix.\nein\"ii->\"(A)  # sum of the diagonal elements of a matrix, i.e., the trace.\nein\"ij->\"(A)  # sum of the elements of a matrix.\nein\"i->ii\"(w)  # create a diagonal matrix.\nein\"i->ij\"(w; size_info=Dict('j'=>2))  # repeat a vector to form a matrix.\nein\"ijk->ikj\"(T1)  # permute the dimensions of a tensor.","category":"section"},{"location":"basic/#Binary-examples","page":"Basic usage","title":"Binary examples","text":"ein\"ij, jk -> ik\"(A, B)  # matrix multiplication.\nein\"ijb,jkb->ikb\"(T1, T2)  # batch matrix multiplication.\nein\"ij,ij->ij\"(A, B)  # element-wise multiplication.\nein\"ij,ij->\"(A, B)  # sum of the element-wise multiplication.\nein\"ij,->ij\"(A, s)  # element-wise multiplication by a scalar.","category":"section"},{"location":"basic/#Nary-examples","page":"Basic usage","title":"Nary examples","text":"optein\"ai,aj,ak->ijk\"(A, A, B)  # star contraction.\noptein\"ia,ajb,bkc,cld,dm->ijklm\"(A, T1, T2, T1, A)  # tensor train contraction.","category":"section"},{"location":"basic/#Computation-Backends","page":"Basic usage","title":"Computation Backends","text":"OMEinsum supports multiple backends for tensor contractions. The backend determines how the underlying computation is performed.","category":"section"},{"location":"basic/#Available-Backends","page":"Basic usage","title":"Available Backends","text":"Backend Description Best For\nDefaultBackend() BLAS/CUBLAS via reshape/permute General use, matrix operations\nCuTensorBackend() NVIDIA cuTENSOR GPU tensor network contractions","category":"section"},{"location":"basic/#Changing-Backends","page":"Basic usage","title":"Changing Backends","text":"get_einsum_backend()  # check current backend\nset_einsum_backend!(DefaultBackend())  # set to default\n\nFor GPU acceleration with cuTENSOR, see CUDA Acceleration.","category":"section"},{"location":"background/#Background-Knowledge","page":"Background: Tensor Networks","title":"Background Knowledge","text":"","category":"section"},{"location":"background/#Tensors-and-Tensor-Networks","page":"Background: Tensor Networks","title":"Tensors and Tensor Networks","text":"Tensor networks serve as a fundamental tool for modeling and analyzing correlated systems. This section reviews the fundamental concepts of tensor networks.\n\nA tensor is a mathematical object that generalizes scalars, vectors, and matrices. It can have multiple dimensions and is used to represent data in various mathematical and physical contexts. It is formally defined as follows:\n\nDefinition (Tensor): A tensor T associated to a set of discrete variables V is defined as a function that maps each possible instantiation of the variables in its scope mathcalD_V = prod_vin V mathcalD_v to an element in the set mathcalE, given by\n\nT_V prod_v in V mathcalD_v rightarrow mathcalE\n\nWithin the context of probabilistic modeling, the elements in mathcalE are non-negative real numbers, while in other scenarios, they can be of generic types. The diagrammatic representation of a tensor is given by a node with the variables V as labels on its edges, as shown below:\n\n<img src=\"../assets/tensors.svg\" width=500 style=\"margin-left:auto; margin-right:auto; display:block\"/>\n\nDefinition (Tensor Network): A tensor network is a mathematical framework for defining multilinear maps, which can be represented by a triple mathcalN = (Lambda mathcalT V_0), where:\n\nLambda is the set of variables present in the network mathcalN.\nmathcalT =  T_V_k _k=1^K is the set of input tensors, where each tensor T_V_k is associated with the labels V_k.\nV_0 specifies the labels of the output tensor.\n\nSpecifically, each tensor T_V_k in mathcalT is labeled by a set of variables V_k subseteq Lambda, where the cardinality V_k equals the rank of T_V_k. The multilinear map, or the contraction, applied to this triple is defined as\n\nT_V_0 = textttcontract(Lambda mathcalT V_0) oversetmathrmdef= sum_m in mathcalD_Lambdasetminus V_0 prod_T_V in mathcalT T_VM=m\n\nwhere M = Lambda setminus V_0. T_VM=m denotes a slicing of the tensor T_V with the variables M fixed to the values m. The summation runs over all possible configurations of the variables in M.\n\nFor instance, matrix multiplication can be described as the contraction of a tensor network given by\n\n(AB)_i k = textttcontractleft(ijk A_i j B_j k i kright)\n\nwhere matrices A and B are input tensors containing the variable sets i j j k, respectively, which are subsets of Lambda = i j k. The output tensor is comprised of variables i k and the summation runs over variables Lambda setminus i k = j. The contraction corresponds to\n\n(A B)_i k = sum_j A_ijB_j k\n\nDiagrammatically, a tensor network can be represented as an open hypergraph, where each tensor is mapped to a vertex and each variable is mapped to a hyperedge. Two vertices are connected by the same hyperedge if and only if they share a common variable. The diagrammatic representation of the matrix multiplication is given as follows: \n\n<img src=\"../assets/matmul.png\" width=500 style=\"margin-left:auto; margin-right:auto; display:block\"/>\n\nHere, we use different colors to denote different hyperedges. Hyperedges for i and k are left open to denote variables of the output tensor. A slightly more complex example of this is the star contraction:\n\ntextttcontract(ijkl A_i l B_j l C_k l ijk) \n= sum_lA_il B_jl C_kl\n\nNote that the variable l is shared by all three tensors, making regular edges, which by definition connect two nodes, insufficient for its representation. This motivates the need for hyperedges, which can connect a single variable to any number of nodes. The hypergraph representation is given as:\n\n<img src=\"../assets/starcontract.png\" width=500 style=\"margin-left:auto; margin-right:auto; display:block\"/>","category":"section"},{"location":"background/#Einsum-notation","page":"Background: Tensor Networks","title":"Einsum notation","text":"The einsum notation is a compact way to specify tensor contractions with a string. In this notation, an index (subscripts) is represented by a char, and the tensors are represented by the indices. The input tensors and the output tensor are separated by an arrow -> and input tensors are separated by comma ,. For example, the matrix multiplication left(ijk A_i j B_j k i kright) can be concisely written as \"ij,jk->ik\". A general contraction can be defined with pseudocode as follows:\n\nLet A, B, C, ... be input tensors, O be the output tensor\nfor indices in domain_of_unique_indices(einsum_notation)\n    O[indices in O] += A[indices in A] * B[indices in B] * ...\nend","category":"section"},{"location":"background/#Examples","page":"Background: Tensor Networks","title":"Examples","text":"einsum notation meaning\nij,jk->ik matrix matrix multiplication\nijl,jkl->ikl batched - matrix matrix multiplication\nij,j->i matrix vector multiplication\nij,ik,il->jkl star contraction\nii-> trace\nij->i sum\nii->i take the diagonal part of a matrix\nijkl->ilkj permute the dimensions of a tensor\ni->ii construct a diagonal matrix\n->ii broadcast a scalar to the diagonal part of a matrix\nij,ij->ij element wise product\nij,kl->ijkl outer product\n\nPlease Einsum examples for code examples.","category":"section"},{"location":"#OMEinsum.jl","page":"Home","title":"OMEinsum.jl","text":"This package provides\n\nThe einsum notation, which is similar to the einsum function in numpy, although some details are different.\nHighly optimized algorithms to optimize the contraction of tensors.\n\nThe source code is available at OMEinsum.jl.","category":"section"},{"location":"#Quick-start","page":"Home","title":"Quick start","text":"You can find a set up guide in the README. To get started, open a Julia REPL and type the following code.\n\nusing OMEinsum\ncode = ein\"ij,jk,kl,lm->im\" # define the einsum operation\noptcode = optimize_code(code, uniformsize(code, 100), TreeSA())  # optimize the contraction order\noptcode(randn(100, 100), randn(100, 100), randn(100, 100), randn(100, 100))  # compute the result","category":"section"},{"location":"autodiff/#Automatic-differentiation","page":"Automatic differentiation","title":"Automatic differentiation","text":"There are two ways to compute the gradient of an einsum expression. The first one is to use the OMEinsum package, which is a custom implementation of the reverse-mode automatic differentiation. The second one is to use the Zygote package, which is a source-to-source automatic differentiation tool.","category":"section"},{"location":"autodiff/#Built-in-automatic-differentiation","page":"Automatic differentiation","title":"Built-in automatic differentiation","text":"The OMEinsum package provides a built-in function cost_and_gradient to compute the cost and the gradient of an einsum expression.\n\nusing OMEinsum  # the 1st way\nA, B, C = randn(2, 3), randn(3, 4), randn(4, 2);\ny, g = cost_and_gradient(ein\"(ij, jk), ki->\", (A, B, C))\n\nThis built-in automatic differentiation is designed for tensor contractions and is more efficient than the general-purpose automatic differentiation tools.\n\nFor complex valued tensors, the automatic differentiation is defined in a convention that treat the real and imaginary parts as independent variables.","category":"section"},{"location":"autodiff/#Using-Zygote","page":"Automatic differentiation","title":"Using Zygote","text":"The backward rule for the basic einsum operation is ported to the ChainRulesCore, which is used by the Zygote package. Zygote is a source-to-source automatic differentiation tool that can be used to compute the gradient of an einsum expression. It is more general and can be used for any Julia code.\n\nusing Zygote  # the 2nd way\nZygote.gradient((A, B, C)->ein\"(ij, jk), ki->\"(A, B, C)[], A, B, C)","category":"section"},{"location":"docstrings/#OMEinsum.CuTensorSupportedTypes","page":"Manual","title":"OMEinsum.CuTensorSupportedTypes","text":"CuTensorSupportedTypes\n\nUnion of numeric types supported by the cuTENSOR backend.\n\nCuTensorSupportedTypes = Union{Float16, Float32, Float64, ComplexF16, ComplexF32, ComplexF64}\n\nArrays with element types not in this union will automatically fall back to the default backend when CuTensorBackend is active.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.CuTensorBackend","page":"Manual","title":"OMEinsum.CuTensorBackend","text":"CuTensorBackend <: EinsumBackend\n\nBackend using NVIDIA cuTENSOR library for native tensor contractions on GPU.\n\nThis backend calls cuTENSOR's contract! function directly, which:\n\nHandles arbitrary tensor contraction patterns natively\nEliminates reshape/permute overhead\nOptimizes memory access patterns internally\n\nRequirements\n\nNVIDIA GPU with compute capability ≥ 6.0\nCUDA.jl v5.0 or later with cuTENSOR support\n\nSupported Types\n\nFloat16, Float32, Float64\nComplexF16, ComplexF32, ComplexF64\n\nFor unsupported types, automatically falls back to DefaultBackend.\n\nPros\n\nNo intermediate allocations for non-GEMM patterns\nBetter performance for tensor network contractions\nNative support for arbitrary index patterns\n\nCons\n\nOnly available on NVIDIA GPUs with cuTENSOR\nSlightly higher overhead for simple GEMM patterns\nLimited to BLAS-compatible numeric types\n\nExample\n\nusing CUDA, cuTENSOR, OMEinsum\n\n# Enable cuTENSOR backend\nset_einsum_backend!(CuTensorBackend())\n\n# Tensor contraction (benefits most from cuTENSOR)\nA = CUDA.rand(Float32, 64, 64, 64)\nB = CUDA.rand(Float32, 64, 64, 64)\nC = ein\"ijk,jkl->il\"(A, B)  # Direct cuTENSOR call, no reshape needed\n\nWhen to Use\n\nTensor network contractions (MPS, PEPS, etc.)\nHigh-dimensional tensor operations\nContractions with complex index patterns like ein\"ijkl,klmn->ijmn\"\n\nSee also: DefaultBackend, set_einsum_backend!\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.DefaultBackend","page":"Manual","title":"OMEinsum.DefaultBackend","text":"DefaultBackend <: EinsumBackend\n\nDefault backend using BLAS/CUBLAS for tensor contractions.\n\nThis backend reduces tensor contractions to matrix multiplications (GEMM) by:\n\nAnalyzing the contraction pattern to identify inner/outer/batch indices\nPermuting tensors to canonical GEMM form if needed\nReshaping tensors to 2D/3D matrices\nCalling optimized BLAS routines (gemm!, gemm_strided_batched!)\nReshaping and permuting the result back\n\nPros\n\nHighly optimized for matrix-like contractions\nWorks with any array type that supports mul!\nNo additional library dependencies\n\nCons\n\nOverhead from permute/reshape for non-GEMM patterns\nMay allocate intermediate arrays\n\nExample\n\nset_einsum_backend!(DefaultBackend())\nein\"ij,jk->ik\"(A, B)  # Uses BLAS gemm\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.DynamicEinCode","page":"Manual","title":"OMEinsum.DynamicEinCode","text":"DynamicEinCode{LT}\nDynamicEinCode(ixs, iy)\n\nWrapper to eincode-specification that creates a callable object to evaluate the eincode ixs -> iy where ixs are the index-labels of the input-tensors and iy are the index-labels of the output.\n\nexample\n\njulia> a, b = rand(2,2), rand(2,2);\n\njulia> OMEinsum.DynamicEinCode((('i','j'),('j','k')),('i','k'))(a, b) ≈ a * b\ntrue\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.DynamicNestedEinsum","page":"Manual","title":"OMEinsum.DynamicNestedEinsum","text":"DynamicNestedEinsum{LT} <: NestedEinsum{LT}\nDynamicNestedEinsum(args, eins)\nDynamicNestedEinsum{LT}(tensorindex::Int)\n\nEinsum with contraction order, where the type parameter LT is the label type. It has two constructors. One takes a tensorindex as input, which represents the leaf node in a contraction tree. The other takes an iterable of type DynamicNestedEinsum, args, as the siblings, and eins to specify the contraction operation.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.EinArray","page":"Manual","title":"OMEinsum.EinArray","text":"EinArray{T, N, TT, LX, LY, ICT, OCT} <: AbstractArray{T, N}\n\nA struct to hold the intermediate result of an einsum where all index-labels of both input and output are expanded to a rank-N-array whose values are lazily calculated. Indices are arranged as inner indices (or reduced dimensions) first and then outer indices.\n\nType parameters are\n\n* `T`: element type,\n* `N`: array dimension,\n* `TT`: type of \"tuple of input arrays\",\n* `LX`: type of \"tuple of input indexers\",\n* `LX`: type of output indexer,\n* `ICT`: typeof inner CartesianIndices,\n* `OCT`: typeof outer CartesianIndices,\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.EinCode","page":"Manual","title":"OMEinsum.EinCode","text":"EinCode <: AbstractEinsum\nEinCode(ixs, iy)\n\nAbstract type for sum-product contraction code. The constructor returns a DynamicEinCode instance.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.EinIndexer","page":"Manual","title":"OMEinsum.EinIndexer","text":"EinIndexer{locs,N}\n\nA structure for indexing EinArrays. locs is the index positions (among all indices). In the constructor, size is the size of target tensor,\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.EinIndexer-Union{Tuple{NTuple{N, Int64}}, Tuple{locs}, Tuple{N}} where {N, locs}","page":"Manual","title":"OMEinsum.EinIndexer","text":"EinIndexer{locs}(size::Tuple)\n\nConstructor for EinIndexer for an object of size size where locs are the locations of relevant indices in a larger tuple.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.EinsumBackend","page":"Manual","title":"OMEinsum.EinsumBackend","text":"EinsumBackend\n\nAbstract type for einsum computation backends.\n\nOMEinsum supports multiple backends for tensor contractions, allowing users to choose the most appropriate implementation for their hardware and use case.\n\nAvailable Backends\n\nDefaultBackend: Uses BLAS/CUBLAS with reshape/permute operations\nCuTensorBackend: Uses NVIDIA cuTENSOR for native tensor contractions\n\nUsage\n\n# Check current backend\nget_einsum_backend()\n\n# Change backend globally\nset_einsum_backend!(CuTensorBackend())\n\nSee also: set_einsum_backend!, get_einsum_backend\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.IndexGroup","page":"Manual","title":"OMEinsum.IndexGroup","text":"IndexGroup\n\nLeaf in a contractiontree, contains the indices and the number of the tensor it describes, e.g. in \"ij,jk -> ik\", indices \"ik\" belong to tensor 1, so would be described by IndexGroup(['i','k'], 1).\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.NestedEinsum","page":"Manual","title":"OMEinsum.NestedEinsum","text":"NestedEinsum{LT} <: AbstractEinsum\n\nThe abstract type for contraction trees. It has two subtypes, DynamicNestedEinsum and StaticNestedEinsum.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.NestedEinsumConstructor","page":"Manual","title":"OMEinsum.NestedEinsumConstructor","text":"NestedEinsumConstructor\n\ndescribes a (potentially) nested einsum. Important fields:\n\nargs, vector of all inputs, either IndexGroup objects corresponding to tensors or NestedEinsumConstructor\niy, indices of output\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.SlicedEinsum","page":"Manual","title":"OMEinsum.SlicedEinsum","text":"SlicedEinsum{LT, Ein} <: AbstractEinsum\n\nA tensor network with slicing. LT is the label type and Ein is the tensor network.\n\nFields\n\nslicing::Vector{LT}: A vector of labels to slice.\neins::Ein: The tensor network.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.StaticEinCode","page":"Manual","title":"OMEinsum.StaticEinCode","text":"StaticEinCode{LT, ixs, iy}\n\nThe static version of DynamicEinCode that matches the contraction rule at compile time. It is the default return type of @ein_str macro. LT is the label type.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsum.StaticNestedEinsum","page":"Manual","title":"OMEinsum.StaticNestedEinsum","text":"StaticNestedEinsum{LT,args,eins} <: NestedEinsum{LT}\nStaticNestedEinsum(args, eins)\nStaticNestedEinsum{LT}(tensorindex::Int)\n\nEinsum with contraction order, where the type parameter LT is the label type, args is a tuple of StaticNestedEinsum, eins is a StaticEinCode and leaf node is defined by setting eins to an integer. It has two constructors. One takes a tensorindex as input, which represents the leaf node in a contraction tree. The other takes an iterable of type DynamicNestedEinsum, args, as the siblings, and eins to specify the contraction operation.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#Base.getindex-Union{Tuple{T}, Tuple{EinArray{T}, Any}} where T","page":"Manual","title":"Base.getindex","text":"getindex(A::EinArray, inds...)\n\nreturn the lazily calculated entry of A at index inds.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.allow_loops-Tuple{Bool}","page":"Manual","title":"OMEinsum.allow_loops","text":"allow_loops(flag::Bool)\n\nSetting this to false will cause OMEinsum to log an error if it falls back to loop_einsum evaluation, instead of calling specialised kernels. The default is true.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.allunique-Tuple{Any}","page":"Manual","title":"OMEinsum.allunique","text":"allunique(ix::Tuple)\n\nreturn true if all elements of ix appear only once in ix.\n\nexample\n\njulia> using OMEinsum: allunique\n\njulia> allunique((1,2,3,4))\ntrue\n\njulia> allunique((1,2,3,1))\nfalse\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.analyze_binary-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}, Vector{T}, Dict{T, Int64}}} where T","page":"Manual","title":"OMEinsum.analyze_binary","text":"Get the expected labels.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.asarray-Tuple{Any}","page":"Manual","title":"OMEinsum.asarray","text":"asarray(x[, parent::AbstractArray]) -> AbstactArray\n\nReturn a 0-dimensional array with item x, otherwise, do nothing. If a parent is supplied, it will try to match the parent array type.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.back_propagate-Union{Tuple{T}, Tuple{Any, SlicedEinsum, OMEinsum.CacheTree{T}, AbstractArray{T}, Dict}} where T","page":"Manual","title":"OMEinsum.back_propagate","text":"back_propagate(f, code, cache, ȳ, size_dict)\n\nBack propagate the message ȳ through the cached tree cache and return a tree storing the intermediate messages. The message can be gradients et al.\n\nArguments\n\nf: The back-propagation rule. The signature is f(eins, xs, y, size_dict, dy) -> dxs, where\neins: The contraction code at the current node.\nxs: The input tensors at the current node.\ny: The output tensor at the current node.\nsize_dict: The size dictionary, which maps the label to the size of the corresponding dimension.\ndy: The message on the output tensor (y) to back-propagate through the current node.\ndxs: The message on the input tensors (xs) as the result of back-propagation.\ncode: The contraction code, which can be a NestedEinsum or a SlicedEinsum.\ncache: The cached intermediate results, which can be generated by cached_einsum.\nȳ: The message to back-propagate.\nsize_dict: The size dictionary, which maps the label to the size of the corresponding dimension.\n\nReturns\n\nCacheTree: The tree storing the intermediate messages.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.cached_einsum-Tuple{SlicedEinsum, Any, Any}","page":"Manual","title":"OMEinsum.cached_einsum","text":"cached_einsum(code, xs, size_dict)\n\nCompute the einsum contraction and cache the intermediate contraction results.\n\nArguments\n\ncode: The contraction code, which can be a NestedEinsum or a SlicedEinsum.\nxs: The input tensors.\nsize_dict: The size dictionary, which maps the label to the size of the corresponding dimension.\n\nReturns\n\nCacheTree: The cached tree storing the intermediate results.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.cost_and_gradient","page":"Manual","title":"OMEinsum.cost_and_gradient","text":"cost_and_gradient(code, xs, ȳ)\n\nCompute the cost and the gradients w.r.t the input tensors xs.\n\nArguments\n\ncode: The contraction code, which can be a NestedEinsum or a SlicedEinsum.\nxs: The input tensors.\nȳ: The message to back-propagate. Default is 1.\n\nReturns\n\ncost: The cost of the contraction.\ngrads: The gradients w.r.t the input tensors.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#OMEinsum.einarray-Union{Tuple{TT}, Tuple{NI}, Tuple{iy}, Tuple{ixs}, Tuple{Val{ixs}, Val{iy}, TT, Any}} where {ixs, iy, NI, TT<:NTuple{NI, AbstractArray}}","page":"Manual","title":"OMEinsum.einarray","text":"einarray(::Val{ixs}, Val{iy}, xs, size_dict) -> EinArray\n\nConstructor of EinArray from an EinCode, a tuple of tensors xs and a size_dict that assigns each index-label a size. The returned EinArray holds an intermediate result of the einsum specified by the EinCode with indices corresponding to all unique labels in the einsum. Reduction over the (lazily calculated) dimensions that correspond to labels not present in the output lead to the result of the einsum.\n\nexample\n\njulia> using OMEinsum: get_size_dict\n\njulia> a, b = rand(2,2), rand(2,2);\n\njulia> sd = get_size_dict((('i','j'),('j','k')), (a, b));\n\njulia> ea = OMEinsum.einarray(Val((('i','j'),('j','k'))),Val(('i','k')), (a,b), sd);\n\njulia> dropdims(sum(ea, dims=1), dims=1) ≈ a * b\ntrue\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.einsum","page":"Manual","title":"OMEinsum.einsum","text":"einsum(code::EinCode, xs, size_dict)\n\nReturn the tensor that results from contracting the tensors xs according to the contraction code code.\n\nArguments\n\ncode: The einsum notation, which can be an instance of EinCode, NestedEinsum, or SlicedEinsum.\nxs - the input tensors\nsize_dict - a dictionary that maps index-labels to their sizes\n\nExamples\n\njulia> a, b = rand(2,2), rand(2,2);\n\njulia> einsum(EinCode((('i','j'),('j','k')),('i','k')), (a, b)) ≈ a * b\ntrue\n\njulia> einsum(EinCode((('i','j'),('j','k')),('k','i')), (a, b)) ≈ permutedims(a * b, (2,1))\ntrue\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#OMEinsum.einsum!","page":"Manual","title":"OMEinsum.einsum!","text":"einsum!(code::EinCode, xs, y, sx, sy, size_dict)\n\nInplace version of einsum. The result is stored in y.\n\nArguments\n\ncode: The einsum notation, which can be an instance of EinCode, NestedEinsum, or SlicedEinsum.\nxs: The input tensors.\ny: The output tensor.\nsx: Scale x by sx.\nsy: Scale y by sy.\nsize_dict: A dictionary that maps index-labels to their sizes.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#OMEinsum.einsum_grad-NTuple{6, Any}","page":"Manual","title":"OMEinsum.einsum_grad","text":"einsum_grad(ixs, xs, iy, size_dict, cdy, i)\n\nreturn the gradient of the result of evaluating the EinCode w.r.t the ith tensor in xs. cdy is the result of applying the EinCode to the xs.\n\nexample\n\njulia> using OMEinsum: einsum_grad, get_size_dict\n\njulia> a, b = rand(2,2), rand(2,2);\n\njulia> c = einsum(EinCode((('i','j'),('j','k')), ('i','k')), (a,b));\n\njulia> sd = get_size_dict((('i','j'),('j','k')), (a,b));\n\njulia> einsum_grad((('i','j'),('j','k')), (a,b), ('i','k'), sd, c, 1) ≈ c * transpose(b)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.filliys!-Tuple{Any}","page":"Manual","title":"OMEinsum.filliys!","text":"filliys!(neinsum::NestedEinsumConstructor)\n\ngoes through all NestedEinsumConstructor objects in the tree and saves the correct iy in them.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.get_einsum_backend-Tuple{}","page":"Manual","title":"OMEinsum.get_einsum_backend","text":"get_einsum_backend() -> EinsumBackend\n\nGet the current global einsum backend.\n\nReturns\n\nThe currently active EinsumBackend instance.\n\nExample\n\nbackend = get_einsum_backend()\nif backend isa CuTensorBackend\n    println(\"Using cuTENSOR\")\nelse\n    println(\"Using default BLAS/CUBLAS\")\nend\n\nSee also: set_einsum_backend!, EinsumBackend\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.get_size_dict!-Union{Tuple{LT}, Tuple{Any, Any, Dict{LT}}} where LT","page":"Manual","title":"OMEinsum.get_size_dict!","text":"get_size_dict!(ixs, xs, size_info)\n\nreturn a dictionary that is used to get the size of an index-label in the einsum-specification with input-indices ixs and tensors xs after consistency within ixs and between ixs and xs has been verified.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.getixsv-Union{Tuple{StaticEinCode{LT}}, Tuple{LT}} where LT","page":"Manual","title":"OMEinsum.getixsv","text":"getixsv(code)\n\nGet labels of input tensors for EinCode, NestedEinsum and some other einsum like objects. Returns a vector of vectors.\n\njulia> getixsv(ein\"(ij,jk),k->i\")\n3-element Vector{Vector{Char}}:\n ['i', 'j']\n ['j', 'k']\n ['k']\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.getiyv-Union{Tuple{StaticEinCode{LT}}, Tuple{LT}} where LT","page":"Manual","title":"OMEinsum.getiyv","text":"getiy(code)\n\nGet labels of the output tensor for EinCode, NestedEinsum and some other einsum like objects. Returns a vector.\n\njulia> getiyv(ein\"(ij,jk),k->i\")\n1-element Vector{Char}:\n 'i': ASCII/Unicode U+0069 (category Ll: Letter, lowercase)\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.indices_and_locs-Tuple{Any, Any}","page":"Manual","title":"OMEinsum.indices_and_locs","text":"indices_and_locs(ixs,iy)\n\ngiven the index-labels of input and output of an einsum, return (in the same order):\n\na tuple of the distinct index-labels of the output iy\na tuple of the distinct index-labels in ixs of the input not appearing in the output iy\na tuple of tuples of locations of an index-label in the ixs in a list of all index-labels\na tuple of locations of index-labels in iy in a list of all index-labels\n\nwhere the list of all index-labels is simply the first  and the second output catenated and the second output catenated.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.loop_einsum!-Union{Tuple{T}, Tuple{L}, Tuple{N}, Tuple{Any, Any, NTuple{N, AbstractArray}, AbstractArray{T, L}, Any, Any, Any}} where {N, L, T}","page":"Manual","title":"OMEinsum.loop_einsum!","text":"loop_einsum!(ixs, iy, xs, y, sx, sy, size_dict)\n\ninplace-version of loop_einsum, saving the result in a preallocated tensor of correct size y.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.loop_einsum-Union{Tuple{N}, Tuple{EinCode, NTuple{N, AbstractArray}, Any}} where N","page":"Manual","title":"OMEinsum.loop_einsum","text":"loop_einsum(::EinCode, xs, size_dict)\n\nevaluates the eincode specified by EinCode and the tensors xs by looping over all possible indices and calculating the contributions ot the result. Scales exponentially in the number of distinct index-labels.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.map_prod-Union{Tuple{N}, Tuple{Tuple, Any, NTuple{N, Any}}} where N","page":"Manual","title":"OMEinsum.map_prod","text":"map_prod(xs, ind, indexers)\n\ncalculate the value of an EinArray with EinIndexers indexers at location ind.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.match_rule-Tuple{Any, Any}","page":"Manual","title":"OMEinsum.match_rule","text":"match_rule(ixs, iy)\nmatch_rule(code::EinCode)\n\nReturns the rule that matches, otherwise use DefaultRule - the slow loop_einsum backend.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.nopermute-Tuple{NTuple{N, T} where {N, T}, NTuple{N, T} where {N, T}}","page":"Manual","title":"OMEinsum.nopermute","text":"nopermute(ix,iy)\n\ncheck that all values in iy that are also in ix have the same relative order,\n\nexample\n\njulia> using OMEinsum: nopermute\n\njulia> nopermute((1,2,3),(1,2))\ntrue\n\njulia> nopermute((1,2,3),(2,1))\nfalse\n\ne.g. nopermute((1,2,3),(1,2)) is true while nopermute((1,2,3),(2,1)) is false\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.parse_parens-Tuple{AbstractString, Any, Any}","page":"Manual","title":"OMEinsum.parse_parens","text":"parse_parens(s::AbstractString, i, narg)\n\nparse one level of parens starting at index i where narg counts which tensor the current group of indices, e.g. \"ijk\", belongs to. Recursively calls itself for each new opening paren that's opened.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.set_einsum_backend!-Tuple{EinsumBackend}","page":"Manual","title":"OMEinsum.set_einsum_backend!","text":"set_einsum_backend!(backend::EinsumBackend) -> EinsumBackend\n\nSet the global backend for einsum operations.\n\nnote: Note\nThis sets a global state. For thread-safe usage in concurrent code, consider using the same backend throughout or synchronizing access.\n\nArguments\n\nbackend::EinsumBackend: The backend to use.\nDefaultBackend(): Use BLAS/CUBLAS (default)\nCuTensorBackend(): Use cuTENSOR for GPU contractions\n\nReturns\n\nThe backend that was set.\n\nExample\n\nusing OMEinsum, CUDA\n\n# Check current backend\nget_einsum_backend()  # DefaultBackend()\n\n# Switch to cuTENSOR\nset_einsum_backend!(CuTensorBackend())\n\n# Perform contractions with cuTENSOR\nA = CUDA.rand(Float32, 100, 200)\nB = CUDA.rand(Float32, 200, 300)\nC = ein\"ij,jk->ik\"(A, B)\n\n# Reset to default\nset_einsum_backend!(DefaultBackend())\n\nPerformance Comparison\n\nusing BenchmarkTools\n\nA = CUDA.rand(Float32, 64, 64, 64)\nB = CUDA.rand(Float32, 64, 64, 64)\n\n# DefaultBackend: requires permute + reshape + GEMM + reshape\nset_einsum_backend!(DefaultBackend())\n@btime CUDA.@sync ein\"ijk,jkl->il\"($A, $B)\n\n# CuTensorBackend: direct tensor contraction\nset_einsum_backend!(CuTensorBackend())\n@btime CUDA.@sync ein\"ijk,jkl->il\"($A, $B)\n\nSee also: get_einsum_backend, EinsumBackend\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.tensorpermute!-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractArray{T, N}, Any, Any, Any}} where {T, N}","page":"Manual","title":"OMEinsum.tensorpermute!","text":"tensorpermute(A, perm)\n\npermutedims(A, perm) with grouped dimensions.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsum.@ein!-Tuple","page":"Manual","title":"OMEinsum.@ein!","text":"@ein! A[i,k] := B[i,j] * C[j,k]     # A = B * C\n@ein! A[i,k] += B[i,j] * C[j,k]     # A += B * C\n@ein! A[i,k] -= B[i,j] * C[j,k]     # A -= B * C\n\nMacro interface similar to that of other packages.\n\nInplace version of @ein. \n\nexample\n\njulia> a, b, c, d = rand(2,2), rand(2,2), rand(2,2), zeros(2,2);\n\njulia> cc = copy(c);\n\njulia> @ein! d[i,k] := a[i,j] * b[j,k];\n\njulia> d ≈ a * b\ntrue\n\njulia> d ≈ ein\"ij,jk -> ik\"(a,b)\ntrue\n\njulia> @ein! c[i,k] += a[i,j] * b[j,k];\n\njulia> c ≈ cc + a * b\ntrue\n\njulia> @ein! c[i,k] -= a[i,j] * b[j,k];\n\njulia> c ≈ cc\ntrue\n\n\n\n\n\n","category":"macro"},{"location":"docstrings/#OMEinsum.@ein-Tuple","page":"Manual","title":"OMEinsum.@ein","text":"@ein A[i,k] := B[i,j] * C[j,k]     # A = B * C\n\nMacro interface similar to that of other packages.\n\nYou may use numbers in place of letters for dummy indices, as in @tensor, and need not name the output array. Thus A = @ein [1,2] := B[1,ξ] * C[ξ,2] is equivalent to the above. This can also be written A = ein\"ij,jk -> ik\"(B,C) using the numpy-style string macro.\n\nexample\n\njulia> a, b = rand(2,2), rand(2,2);\n\njulia> @ein c[i,k] := a[i,j] * b[j,k];\n\njulia> c ≈ a * b\ntrue\n\njulia> c ≈ ein\"ij,jk -> ik\"(a,b)\ntrue\n\n\n\n\n\n","category":"macro"},{"location":"docstrings/#OMEinsum.@ein_str-Tuple{AbstractString}","page":"Manual","title":"OMEinsum.@ein_str","text":"ein\"ij,jk -> ik\"(A,B)\n\nString macro interface which understands numpy.einsum's notation. Translates strings into StaticEinCode-structs that can be called to evaluate an einsum. To control evaluation order, use parentheses - instead of an EinCode, a NestedEinsum is returned which evaluates the expression according to parens. The valid character ranges for index-labels are a-z and α-ω.\n\nexample\n\njulia> a, b, c = rand(10,10), rand(10,10), rand(10,1);\n\njulia> ein\"ij,jk,kl -> il\"(a,b,c) ≈ ein\"(ij,jk),kl -> il\"(a,b,c) ≈ a * b * c\ntrue\n\n\n\n\n\n","category":"macro"},{"location":"docstrings/#OMEinsum.@optein_str-Tuple{AbstractString}","page":"Manual","title":"OMEinsum.@optein_str","text":"optein\"ij,jk,kl -> ik\"(A, B, C)\n\nString macro interface that similar to @ein_str, with optimized contraction order (dimensions are assumed to be uniform).\n\n\n\n\n\n","category":"macro"},{"location":"docstrings/#OMEinsumContractionOrders.AbstractDecompositionType","page":"Manual","title":"OMEinsumContractionOrders.AbstractDecompositionType","text":"AbstractDecompositionType\n\nAbstract type for decomposition types, which includes TreeDecomp and PathDecomp.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.AbstractEinsum","page":"Manual","title":"OMEinsumContractionOrders.AbstractEinsum","text":"AbstractEinsum\n\nAbstract type for einsum notations.\n\nRequired Interfaces\n\ngetixsv: a vector of vectors, each vector represents the labels associated with a input tensor.\ngetiyv: a vector of labels associated with the output tensor.\nuniquelabels: a vector of labels that are unique in the einsum notation.\n\nDerived interfaces\n\nlabeltype: the data type to represent the labels in the einsum notation.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.BipartiteResult","page":"Manual","title":"OMEinsumContractionOrders.BipartiteResult","text":"BipartiteResult{RT}\nBipartiteResult(part1, part2, sc, valid)\n\nResult of the bipartite optimization. part1 and part2 are the two parts of the bipartition, sc is the space complexity of the bipartition, valid is a boolean indicating whether the bipartition is valid.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.CodeOptimizer","page":"Manual","title":"OMEinsumContractionOrders.CodeOptimizer","text":"CodeOptimizer\n\nAbstract type for code optimizers.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.CodeSimplifier","page":"Manual","title":"OMEinsumContractionOrders.CodeSimplifier","text":"CodeSimplifier\n\nAbstract type for code simplifiers.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.CodeSlicer","page":"Manual","title":"OMEinsumContractionOrders.CodeSlicer","text":"CodeSlicer\n\nAbstract type for code slicers.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.EinCode","page":"Manual","title":"OMEinsumContractionOrders.EinCode","text":"EinCode{LT} <: AbstractEinsum\nEinCode(ixs::Vector{Vector{LT}}, iy::Vector{LT})\n\nEinsum code with input indices ixs and output index iy.\n\nExamples\n\nThe einsum notation for matrix multiplication is:\n\njulia> code = OMEinsumContractionOrders.EinCode([[1,2], [2, 3]], [1, 3])\n1∘2, 2∘3 -> 1∘3\n\njulia> OMEinsumContractionOrders.getixsv(code)\n2-element Vector{Vector{Int64}}:\n [1, 2]\n [2, 3]\n\njulia> OMEinsumContractionOrders.getiyv(code)\n2-element Vector{Int64}:\n 1\n 3\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.ExactTreewidth","page":"Manual","title":"OMEinsumContractionOrders.ExactTreewidth","text":"const ExactTreewidth = Treewidth{SafeRules{BT, MMW{3}(), MF}}\nExactTreewidth() = Treewidth()\n\nExactTreewidth is a specialization of Treewidth for the SafeRules preprocessing algorithm with the BT elimination algorithm. The BT algorithm is an exact solver for the treewidth problem that implemented in TreeWidthSolver.jl.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.GreedyMethod","page":"Manual","title":"OMEinsumContractionOrders.GreedyMethod","text":"GreedyMethod{MT}\nGreedyMethod(; α = 0.0, temperature = 0.0)\n\nIt may not be optimal, but it is fast.\n\nFields\n\nα is the parameter for the loss function, for pairwise interaction, L = size(out) - α * (size(in1) + size(in2))\ntemperature is the parameter for sampling, if it is zero, the minimum loss is selected; for non-zero, the loss is selected by the Boltzmann distribution, given by p ~ exp(-loss/temperature).\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.HyperND","page":"Manual","title":"OMEinsumContractionOrders.HyperND","text":"HyperND(;\n    dis = KaHyParND(),\n    algs = (MF(), AMF(), MMD()),\n    level = 6,\n    width = 120,\n    scale = 100,\n    imbalances = 130:130,\n    score = ScoreFunction(),\n)\n\nNested-dissection based optimizer. Recursively partitions a tensor network, then calls a greedy algorithm on the leaves. The optimizer is run a number of times: once for each greedy algorithm in algs and each imbalance value in imbalances. The recursion depth is controlled by the parameters level and width. The parameter scale controls discretization of the index weights:\n\nweight(i) := scale * log2(dim(i))\n\nwhere dim(i) is the dimension of the index i.\n\nThe line graph is partitioned using the algorithm dis. OMEinsumContractionOrders currently supports two partitioning algorithms, both of which require importing an external library.\n\ntype package\nMETISND Metis.jl\nKaHyParND KayHyPar.jl\n\nThe optimizer is implemented using the tree decomposition library CliqueTrees.jl.\n\nArguments\n\ndis: graph partitioning algorithm\nalgs: tuple of elimination algorithms.\nlevel: maximum level\nwidth: minimum width\nimbalances: imbalance parameters \nscore: a function to evaluate the quality of the contraction tree. Default is ScoreFunction().\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.KaHyParBipartite","page":"Manual","title":"OMEinsumContractionOrders.KaHyParBipartite","text":"KaHyParBipartite{RT,IT,GM}\nKaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),\n    max_group_size=40, greedy_config=GreedyMethod())\n\nOptimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by max_group_size and maximum space complexity specified by sc_target, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are\n\nFields\n\nsc_target is the target space complexity, defined as log2(number of elements in the largest tensor),\nimbalances is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,\nmax_group_size is the maximum size that allowed to used greedy search,\nsub_optimizer is the sub-optimizer used to find the contraction order when the group size is small enough.\n\nReferences\n\nHyper-optimized tensor network contraction\nSimulating the Sycamore quantum supremacy circuits\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.MergeGreedy","page":"Manual","title":"OMEinsumContractionOrders.MergeGreedy","text":"MergeGreedy <: CodeSimplifier\nMergeGreedy(; threshhold=-1e-12)\n\nContraction code simplifier (in order to reduce the time of calling optimizers) that merges tensors greedily if the space complexity of merged tensors is reduced (difference smaller than the threshhold).\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.MergeVectors","page":"Manual","title":"OMEinsumContractionOrders.MergeVectors","text":"MergeVectors <: CodeSimplifier\nMergeVectors()\n\nContraction code simplifier (in order to reduce the time of calling optimizers) that merges vectors to closest tensors.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.NestedEinsum","page":"Manual","title":"OMEinsumContractionOrders.NestedEinsum","text":"NestedEinsum{LT} <: AbstractEinsum\nNestedEinsum(args::Vector{NestedEinsum}, eins::EinCode)\n\nThe einsum notation with a contraction order specified as a tree data structure. It is automatically generated by the contraction code optimizer with the optimize_code function.\n\nFields\n\nargs: the children of the current node\ntensorindex: the index of the input tensor, required only for leaf nodes. For non-leaf nodes, it is -1.\neins: the einsum notation for the operation at the current node.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.NetworkSimplifier","page":"Manual","title":"OMEinsumContractionOrders.NetworkSimplifier","text":"NetworkSimplifier{LT}\n\nA network simplifier that contains a list of operations that can be applied to a tensor network to reduce the number of tensors. It is generated from a proprocessor, such as MergeVectors or MergeGreedy.\n\nFields\n\noperations: a list of NestedEinsum objects.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.PathDecomp","page":"Manual","title":"OMEinsumContractionOrders.PathDecomp","text":"PathDecomp <: AbstractDecompositionType\n\nPath decomposition type.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.PathSA-Tuple{}","page":"Manual","title":"OMEinsumContractionOrders.PathSA","text":"PathSA(; βs=0.01:0.05:15, ntrials=10, niters=50, score=ScoreFunction())\n\nOptimize the einsum contraction pattern using the simulated annealing on tensor expression tree, with path decomposition.\n\nFields\n\nβs, ntrials, niters and score are the same as in TreeSA.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.SABipartite","page":"Manual","title":"OMEinsumContractionOrders.SABipartite","text":"SABipartite{RT,BT}\nSABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000\n    max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)\n\nOptimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by max_group_size and maximum space complexity specified by sc_target, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are\n\nFields\n\nsc_target is the target space complexity, defined as log2(number of elements in the largest tensor),\nntrials is the number of repetition (with different random seeds),\nβs is a list of inverse temperature 1/T,\nniters is the number of iteration in each temperature,\nmax_group_size is the maximum size that allowed to used greedy search,\nsub_optimizer is the optimizer for the bipartited sub graphs, one can choose GreedyMethod() or TreeSA(),\ninitializer is the partition configuration initializer, one can choose :random or :greedy (slow but better).\n\nReferences\n\nHyper-optimized tensor network contraction\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.ScoreFunction","page":"Manual","title":"OMEinsumContractionOrders.ScoreFunction","text":"ScoreFunction\n\nA function to compute the score of a contraction code:\n\nscore = tc_weight * 2^tc + rw_weight * 2^rw + sc_weight * max(0, 2^sc - 2^sc_target)\n\nFields\n\ntc_weight: the weight of the time complexity, default is 1.0.\nsc_weight: the weight of the space complexity (the size of the largest tensor), default is 1.0.\nrw_weight: the weight of the read-write complexity, default is 0.0.\nsc_target: the target space complexity, below which the sc_weight will be set to 0 automatically, default is 0.0.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.SlicedEinsum","page":"Manual","title":"OMEinsumContractionOrders.SlicedEinsum","text":"SlicedEinsum{LT,ET<:Union{EinCode{LT},NestedEinsum{LT}}} <: AbstractEinsum\nSlicedEinsum(slicing::Vector{LT}, eins::ET)\n\nThe einsum notation with sliced indices. The sliced indices are the indices enumerated manually at the top level. By slicing the indices, the space complexity of the einsum notation can be reduced.\n\nFields\n\nslicing: the sliced indices.\neins: the einsum notation of the current node, which is a NestedEinsum object.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.TreeDecomp","page":"Manual","title":"OMEinsumContractionOrders.TreeDecomp","text":"TreeDecomp <: AbstractDecompositionType\n\nTree decomposition type.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.TreeSA","page":"Manual","title":"OMEinsumContractionOrders.TreeSA","text":"TreeSA{IT, DT} <: CodeOptimizer\nTreeSA(; βs=collect(0.01:0.05:15), ntrials=10, niters=50, initializer=:greedy, score=ScoreFunction(), decomposition_type=TreeDeomp())\n\nOptimize the einsum contraction pattern using the simulated annealing on tensor expression tree.\n\nFields\n\nntrials, βs and niters are annealing parameters, doing ntrials indepedent annealings, each has inverse tempteratures specified by βs, in each temperature, do niters updates of the tree.\ninitializer specifies how to determine the initial configuration, it can be :greedy, :random or :specified. If the initializer is :specified, the input code should be a NestedEinsum object.\nscore specifies the score function to evaluate the quality of the contraction tree, it is a function of time complexity, space complexity and read-write complexity.\ndecomposition_type specifies the type of decomposition to use, it can be TreeDeomp or PathDecomp.\n\nReferences\n\nRecursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits\n\nBreaking changes:\n\nnslices is removed, since the slicing part is now separated from the optimization part, see slice_code function and TreeSASlicer.\ngreedy_method is removed. If you want to have detailed control of the initializer, please pre-optimize the code with another method and then use :specified to initialize the tree.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.TreeSASlicer","page":"Manual","title":"OMEinsumContractionOrders.TreeSASlicer","text":"TreeSASlicer{IT, LT} <: CodeSlicer\n\nA structure for configuring the Tree Simulated Annealing (TreeSA) slicing algorithm. The goal of slicing is to reach the target space complexity specified by score.sc_target.\n\nFields\n\nntrials, βs and niters are annealing parameters, doing ntrials indepedent annealings, each has inverse tempteratures specified by βs, in each temperature, do niters updates of the tree.\nfixed_slices::Vector{LT}: A vector of fixed slices that should not be altered. Default is an empty vector.\noptimization_ratio::Float64: A constant used for determining the number of iterations for slicing. Default is 2.0. i.e. if the current space complexity is 30, and the target space complexity is 20, then the number of iterations for slicing is (30 - 20) x optimization_ratio.\nscore::ScoreFunction: A function to evaluate the quality of the contraction tree. Default is ScoreFunction(sc_target=30.0).\ndecomposition_type::AbstractDecompositionType: The type of decomposition to use. Default is TreeDecomp().\n\nReferences\n\nRecursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.Treewidth","page":"Manual","title":"OMEinsumContractionOrders.Treewidth","text":"struct Treewidth{EL <: EliminationAlgorithm, GM} <: CodeOptimizer\nTreewidth(; alg::EL = SafeRules(BT(), MMW{3}(), MF()))\n\nTree width based solver. The solvers are implemented in CliqueTrees.jl and TreeWidthSolver.jl. They include:\n\nAlgorithm Description Time Complexity Space Complexity\nAMF approximate minimum fill O(mn) O(m + n)\nMF minimum fill O(mn²) -\nMMD multiple minimum degree O(mn²) O(m + n)\n\nDetailed descriptions is available in the CliqueTrees.jl.\n\nFields\n\nalg::EL: The algorithm to use for the treewidth calculation. Available elimination algorithms are listed above.\n\nExample\n\njulia> optimizer = Treewidth();\n\njulia> eincode = OMEinsumContractionOrders.EinCode([['a', 'b'], ['a', 'c', 'd'], ['b', 'c', 'e', 'f'], ['e'], ['d', 'f']], ['a'])\nab, acd, bcef, e, df -> a\n\njulia> size_dict = Dict([c=>(1<<i) for (i,c) in enumerate(['a', 'b', 'c', 'd', 'e', 'f'])]...)\nDict{Char, Int64} with 6 entries:\n  'f' => 64\n  'a' => 2\n  'c' => 8\n  'd' => 16\n  'e' => 32\n  'b' => 4\n\njulia> optcode = optimize_code(eincode, size_dict, optimizer)\nab, ba -> a\n├─ ab\n└─ bcf, acf -> ba\n   ├─ bcef, e -> bcf\n   │  ├─ bcef\n   │  └─ e\n   └─ acd, df -> acf\n      ├─ acd\n      └─ df\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#OMEinsumContractionOrders.compute_contraction_dims-NTuple{6, Any}","page":"Manual","title":"OMEinsumContractionOrders.compute_contraction_dims","text":"compute_contraction_dims(incidence_list, log2_edge_sizes, vi, vj, eout, eremove) -> (D1, D2, D12, D01, D02, D012)\n\nCompute the log2 dimensions and edge lists for contracting vertices vi and vj. Returns a tuple of six Float64 dimension values:\n\nD1: edges only in vi and internal\nD2: edges only in vj and internal\nD12: edges in both vi and vj and internal\nD01: edges only in vi and external\nD02: edges only in vj and external\nD012: edges in both vi and vj and external\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.contraction_complexity-Tuple{OMEinsumContractionOrders.AbstractEinsum, Any}","page":"Manual","title":"OMEinsumContractionOrders.contraction_complexity","text":"contraction_complexity(eincode, size_dict) -> ContractionComplexity\n\nReturns the time, space and read-write complexity of the einsum contraction. The returned ContractionComplexity object contains 3 fields:\n\ntc: time complexity defined as log2(number of element-wise multiplications).\nsc: space complexity defined as log2(size of the maximum intermediate tensor).\nrwc: read-write complexity defined as log2(the number of read-write operations).\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.convert_label-Union{Tuple{T2}, Tuple{T1}, Tuple{OMEinsumContractionOrders.NestedEinsum, Dict{T1, T2}}} where {T1, T2}","page":"Manual","title":"OMEinsumContractionOrders.convert_label","text":"convert_label(ne::NestedEinsum, labelmap::Dict{T1,T2}) where {T1,T2}\n\nConvert the labels of a NestedEinsum object to new labels. labelmap is a dictionary that maps the old labels to the new labels.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.einexpr_to_matrix!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, AbstractVector{<:AbstractVector{L}}, AbstractVector{L}, AbstractDict{L}}} where L","page":"Manual","title":"OMEinsumContractionOrders.einexpr_to_matrix!","text":"einexpr_to_matrix!(marker, ixs, iy, size_dict)\n\nConstruct the weighted incidence matrix correponding to an Einstein summation expression. Returns a quadruple (weights, ev, ve, el).\n\nEach Einstein summation expression has a set E ⊆ L of indices, a set V := {1, …, |V|} of (inner) tensors, and an outer tensor * := |V| + 1. Each tensor v ∈ V is incident to a sequence ixs[v] of indices, and the outer tensor is incident to the sequence iy. Note that an index can appear multiple times in ixs[v], e.g.\n\nixs[v] = ('a', 'a', 'b').\n\nEach index l ∈ E also has a positive dimension, given by size_dict[l].\n\nThe function einexpr_to_matrix does two things. First of all, it enumerates the index set E, mapping each index to a distinct natural number.\n\nel: {1, …, |E|} → E\nle: E → {1, …, |E|}\n\nNext, it constructs a vector weights: {1, …, |E|} → [0, ∞) satisfying\n\nweights[e] := log2(size_dict[el[e]]),\n\nand a sparse matrix ve: {1, …, |V| + 1} × {1, …, |E|} → {0, 1} satisfying\n\nve[v, e] := { 1 if el[e] is incident to v\n            { 0 otherwise\n\nWe can think of the pair H := (weights, ve) as an edge-weighted hypergraph with incidence matrix ve.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.embed_simplifier-Tuple{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.NetworkSimplifier}","page":"Manual","title":"OMEinsumContractionOrders.embed_simplifier","text":"embed_simplifier(code::NestedEinsum, simplifier::NetworkSimplifier)\n\nEmbed the simplifier into the contraction code. A typical workflow is: (i) generate a simplifier with simplify_code, (ii) then optimize the simplified code with optimize_code and (iii) post-process the optimized code with embed_simplifier to produce correct contraction order for the original code. This is automatically done in optimize_code given the simplifier argument is not nothing.\n\nArguments\n\ncode: the contraction code to embed the simplifier into.\nsimplifier: the simplifier to embed, which is a NetworkSimplifier object.\n\nReturns\n\nA new NestedEinsum object.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.flop-Union{Tuple{VT}, Tuple{LT}, Tuple{OMEinsumContractionOrders.EinCode, Dict{LT, VT}}} where {LT, VT}","page":"Manual","title":"OMEinsumContractionOrders.flop","text":"flop(eincode, size_dict) -> Int\n\nReturns the number of iterations, which is different with the true floating point operations (FLOP) by a factor of 2.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.getixsv","page":"Manual","title":"OMEinsumContractionOrders.getixsv","text":"getixsv(code::AbstractEinsum) -> Vector{Vector{LT}}\n\nReturns the input indices of the einsum notation. Each vector represents the labels associated with a input tensor.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#OMEinsumContractionOrders.getiyv","page":"Manual","title":"OMEinsumContractionOrders.getiyv","text":"getiyv(code::AbstractEinsum) -> Vector{LT}\n\nReturns the output index of the einsum notation.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#OMEinsumContractionOrders.label_elimination_order-Tuple{OMEinsumContractionOrders.NestedEinsum}","page":"Manual","title":"OMEinsumContractionOrders.label_elimination_order","text":"label_elimination_order(code) -> Vector\n\nReturns a vector of labels sorted by the order they are eliminated in the contraction tree. The contraction tree is specified by code, which e.g. can be a NestedEinsum instance.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.labeltype-Tuple{OMEinsumContractionOrders.AbstractEinsum}","page":"Manual","title":"OMEinsumContractionOrders.labeltype","text":"labeltype(code::AbstractEinsum) -> Type\n\nReturns the data type to represent the labels in the einsum notation.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.matrix_to_tree!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, AbstractVector{Float64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, AbstractVector{L}, CliqueTrees.EliminationAlgorithm}} where L","page":"Manual","title":"OMEinsumContractionOrders.matrix_to_tree!","text":"matrix_to_tree!(marker, weights, ev, ve, el, alg)\n\nConstruct a tree decomposition of an edge-weighted hypergraph using the elimination algorithm alg. We ensure that the indices incident to the outer tensor are contained in the root bag of the tree decomposition.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.optimize_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Dict, CodeOptimizer}","page":"Manual","title":"OMEinsumContractionOrders.optimize_code","text":"optimize_code(eincode, size_dict, optimizer = GreedyMethod(); slicer=nothing, simplifier=nothing, permute=true) -> optimized_eincode\n\nOptimize the einsum contraction code and reduce the time/space complexity of tensor network contraction. Returns a NestedEinsum instance. Input arguments are\n\nArguments\n\neincode is an einsum contraction code instance, one of DynamicEinCode, StaticEinCode or NestedEinsum.\nsize is a dictionary of \"edge label=>edge size\" that contains the size information, one can use uniformsize(eincode, 2) to create a uniform size.\noptimizer is a CodeOptimizer instance, should be one of GreedyMethod, Treewidth, KaHyParBipartite, SABipartite or TreeSA. Check their docstrings for details.\n\nKeyword Arguments\n\nslicer is for slicing the contraction code to reduce the space complexity, default is nothing. Currently only TreeSASlicer is supported.\nsimplifier is one of MergeVectors or MergeGreedy. Default is nothing.\npermute is a boolean flag to indicate whether to optimize the permutation of the contraction order.\n\nExamples\n\njulia> using OMEinsum\n\njulia> code = ein\"ij, jk, kl, il->\"\nij, jk, kl, il -> \n\njulia> optimize_code(code, uniformsize(code, 2), TreeSA());\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.optimize_greedy-Union{Tuple{T2}, Tuple{L}, Tuple{OMEinsumContractionOrders.AbstractEinsum, Dict{L, T2}}} where {L, T2}","page":"Manual","title":"OMEinsumContractionOrders.optimize_greedy","text":"optimize_greedy(eincode, size_dict; α, temperature)\n\nGreedy optimizing the contraction order and return a NestedEinsum object. Check the docstring of tree_greedy for detailed explaination of other input arguments.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.optimize_sa-Tuple{OMEinsumContractionOrders.EinCode, Any}","page":"Manual","title":"OMEinsumContractionOrders.optimize_sa","text":"optimize_sa(code, size_dict; sc_target, max_group_size=40, βs=0.1:0.2:15.0, niters=1000, ntrials=50,\n       sub_optimizer = GreedyMethod(), initializer=:random)\n\nOptimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. size_dict is a dictionary that specifies leg dimensions.  Check the docstring of SABipartite for detailed explaination of other input arguments.\n\nReferences\n\nHyper-optimized tensor network contraction\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.optimize_tree-Union{Tuple{LT}, Tuple{OMEinsumContractionOrders.AbstractEinsum, Dict{LT, Int64}}} where LT","page":"Manual","title":"OMEinsumContractionOrders.optimize_tree","text":"optimize_tree(code, size_dict; βs, ntrials, niters, initializer, score)\n\nOptimize the einsum contraction pattern specified by code, and edge sizes specified by size_dict. Check the docstring of TreeSA for detailed explaination of other input arguments.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.optimize_treewidth-Tuple{OMEinsumContractionOrders.Treewidth, OMEinsumContractionOrders.AbstractEinsum, Dict}","page":"Manual","title":"OMEinsumContractionOrders.optimize_treewidth","text":"optimize_treewidth(optimizer, eincode, size_dict)\n\nOptimizing the contraction order via solve the exact tree width of the line graph corresponding to the eincode and return a NestedEinsum object. Check the docstring of treewidth_method for detailed explaination of other input arguments.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.peak_memory-Tuple{OMEinsumContractionOrders.NestedEinsum, Dict}","page":"Manual","title":"OMEinsumContractionOrders.peak_memory","text":"peak_memory(code, size_dict::Dict) -> Int\n\nEstimate peak memory in number of elements.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.readjson-Tuple{AbstractString}","page":"Manual","title":"OMEinsumContractionOrders.readjson","text":"readjson(filename::AbstractString)\n\nRead the contraction order from a JSON file.\n\nArguments\n\nfilename: the name of the file to read from.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.simplify_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Any, MergeVectors}","page":"Manual","title":"OMEinsumContractionOrders.simplify_code","text":"simplify_code(code::Union{EinCode, NestedEinsum}, size_dict, method::CodeSimplifier)\n\nSimplify the contraction code by preprocessing the code with a simplifier.\n\nArguments\n\ncode: the contraction code to simplify.\nsize_dict: the size dictionary of the contraction code.\nmethod: the simplifier to use, which can be MergeVectors or MergeGreedy.\n\nReturns\n\nA tuple of (NetworkSimplifier, newcode), where newcode is a new EinCode object.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.slice_code-Tuple{OMEinsumContractionOrders.NestedEinsum, Any, TreeSASlicer}","page":"Manual","title":"OMEinsumContractionOrders.slice_code","text":"slice_code(code, size_dict, slicer) -> sliced_code\n\nSlice the einsum contraction code to reduce the space complexity, returns a SlicedEinsum instance.\n\nArguments\n\ncode is a NestedEinsum instance.\nsize_dict is a dictionary of \"edge label=>edge size\" that contains the size information, one can use uniformsize(eincode, 2) to create a uniform size.\nslicer is a CodeSlicer instance, currently only TreeSASlicer is supported.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.tree_greedy-Union{Tuple{ET}, Tuple{TT}, Tuple{TA}, Tuple{OMEinsumContractionOrders.IncidenceList{Int64, ET}, Any}} where {TA, TT, ET}","page":"Manual","title":"OMEinsumContractionOrders.tree_greedy","text":"tree_greedy(incidence_list, log2_sizes; α = 0.0, temperature = 0.0)\n\nCompute greedy order, and the time and space complexities, the rows of the incidence_list are vertices and columns are edges. log2_sizes are defined on edges. α is the parameter for the loss function, for pairwise interaction, L = size(out) - α * (size(in1) + size(in2)) temperature is the parameter for sampling, if it is zero, the minimum loss is selected; for non-zero, the loss is selected by the Boltzmann distribution, given by p ~ exp(-loss/temperature).\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.tree_to_einexpr!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, CliqueTrees.CliqueTree{Int64, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, AbstractVector{L}, AbstractVector{<:AbstractVector{L}}, AbstractVector{L}}} where L","page":"Manual","title":"OMEinsumContractionOrders.tree_to_einexpr!","text":"tree_to_einexpr!(marker, tree, ve, el, ixs, iy)\n\nTransform a tree decomposition into a contraction tree.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.uniformsize-Tuple{OMEinsumContractionOrders.AbstractEinsum, Any}","page":"Manual","title":"OMEinsumContractionOrders.uniformsize","text":"uniformsize(code::AbstractEinsum, size::Int) -> Dict\n\nReturns a dictionary that maps each label to the given size.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.uniquelabels-Tuple{OMEinsumContractionOrders.AbstractEinsum}","page":"Manual","title":"OMEinsumContractionOrders.uniquelabels","text":"uniquelabels(code::AbstractEinsum) -> Vector{LT}\n\nReturns the unique labels in the einsum notation. The labels are the indices of the tensors.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.viz_contraction-Tuple","page":"Manual","title":"OMEinsumContractionOrders.viz_contraction","text":"viz_contraction(code::Union{NestedEinsum, SlicedEinsum}; locs=StressLayout(), framerate=10, filename=tempname() * \".mp4\", show_progress=true)\n\nVisualize the contraction process of a tensor network.\n\nArguments\n\ncode: The tensor network to visualize.\n\nKeyword Arguments\n\nlocs: The coordinates or layout algorithm to use for positioning the nodes in the graph. Default is StressLayout().\nframerate: The frame rate of the animation. Default is 10.\nfilename: The name of the output file, with .gif or .mp4 extension. Default is a temporary file with .mp4 extension.\nshow_progress: Whether to show progress information. Default is true.\n\nReturns\n\nthe path of the generated file.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.viz_eins-Tuple","page":"Manual","title":"OMEinsumContractionOrders.viz_eins","text":"viz_eins(code::AbstractEinsum; locs=StressLayout(), filename = nothing, kwargs...)\n\nVisualizes an AbstractEinsum object by creating a tensor network graph and rendering it using GraphViz.\n\nArguments\n\ncode::AbstractEinsum: The AbstractEinsum object to visualize.\n\nKeyword Arguments\n\nlocs=StressLayout(): The coordinates or layout algorithm to use for positioning the nodes in the graph.\nfilename = nothing: The name of the file to save the visualization to. If nothing, the visualization will be displayed on the screen instead of saving to a file.\nconfig = GraphDisplayConfig(): The configuration for displaying the graph. Please refer to the documentation of GraphDisplayConfig for more information.\nkwargs...: Additional keyword arguments to be passed to the GraphViz constructor.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#OMEinsumContractionOrders.writejson-Tuple{AbstractString, Union{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.SlicedEinsum}}","page":"Manual","title":"OMEinsumContractionOrders.writejson","text":"writejson(filename::AbstractString, ne::Union{NestedEinsum, SlicedEinsum})\n\nWrite the contraction order to a JSON file.\n\nArguments\n\nfilename: the name of the file to write to.\nne: the contraction order to write. It can be a NestedEinsum or a SlicedEinsum object.\n\n\n\n\n\n","category":"method"}]
}
