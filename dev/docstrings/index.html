<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Manual · OMEinsum.jl</title><meta name="title" content="Manual · OMEinsum.jl"/><meta property="og:title" content="Manual · OMEinsum.jl"/><meta property="twitter:title" content="Manual · OMEinsum.jl"/><meta name="description" content="Documentation for OMEinsum.jl."/><meta property="og:description" content="Documentation for OMEinsum.jl."/><meta property="twitter:description" content="Documentation for OMEinsum.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">OMEinsum.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../background/">Background: Tensor Networks</a></li><li><a class="tocitem" href="../basic/">Basic usage</a></li><li><a class="tocitem" href="../contractionorder/">Contraction order optimization</a></li><li><a class="tocitem" href="../autodiff/">Automatic differentiation</a></li><li><a class="tocitem" href="../cuda/">CUDA</a></li><li><a class="tocitem" href="../applications/">Applications</a></li><li class="is-active"><a class="tocitem" href>Manual</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Manual</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Manual</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/under-Peter/OMEinsum.jl/blob/master/docs/src/docstrings.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><article><details class="docstring" open="true"><summary id="OMEinsum.CuTensorSupportedTypes"><a class="docstring-binding" href="#OMEinsum.CuTensorSupportedTypes"><code>OMEinsum.CuTensorSupportedTypes</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CuTensorSupportedTypes</code></pre><p>Union of numeric types supported by the cuTENSOR backend.</p><pre><code class="language-julia hljs">CuTensorSupportedTypes = Union{Float16, Float32, Float64, ComplexF16, ComplexF32, ComplexF64}</code></pre><p>Arrays with element types not in this union will automatically fall back to the default backend when <code>CuTensorBackend</code> is active.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/backends.jl#LL225-L236">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.CuTensorBackend"><a class="docstring-binding" href="#OMEinsum.CuTensorBackend"><code>OMEinsum.CuTensorBackend</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CuTensorBackend &lt;: EinsumBackend</code></pre><p>Backend using NVIDIA cuTENSOR library for native tensor contractions on GPU.</p><p>This backend calls cuTENSOR&#39;s <code>contraction!</code> function directly, which:</p><ul><li>Handles arbitrary tensor contraction patterns natively</li><li>Eliminates reshape/permute overhead</li><li>Optimizes memory access patterns internally</li></ul><p><strong>Requirements</strong></p><ul><li>NVIDIA GPU with compute capability ≥ 6.0</li><li>CUDA.jl v5.0 or later with cuTENSOR support</li></ul><p><strong>Supported Types</strong></p><ul><li><code>Float16</code>, <code>Float32</code>, <code>Float64</code></li><li><code>ComplexF16</code>, <code>ComplexF32</code>, <code>ComplexF64</code></li></ul><p>For unsupported types, automatically falls back to <code>DefaultBackend</code>.</p><p><strong>Pros</strong></p><ul><li>No intermediate allocations for non-GEMM patterns</li><li>Better performance for tensor network contractions</li><li>Native support for arbitrary index patterns</li></ul><p><strong>Cons</strong></p><ul><li>Only available on NVIDIA GPUs with cuTENSOR</li><li>Slightly higher overhead for simple GEMM patterns</li><li>Limited to BLAS-compatible numeric types</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">using CUDA, OMEinsum

# Check if cuTENSOR is available
ext = Base.get_extension(OMEinsum, :CUDAExt)
ext.has_cutensor()  # true if available

# Enable cuTENSOR backend
set_einsum_backend!(CuTensorBackend())

# Tensor contraction (benefits most from cuTENSOR)
A = CUDA.rand(Float32, 64, 64, 64)
B = CUDA.rand(Float32, 64, 64, 64)
C = ein&quot;ijk,jkl-&gt;il&quot;(A, B)  # Direct cuTENSOR call, no reshape needed</code></pre><p><strong>When to Use</strong></p><ul><li>Tensor network contractions (MPS, PEPS, etc.)</li><li>High-dimensional tensor operations</li><li>Contractions with complex index patterns like <code>ein&quot;ijkl,klmn-&gt;ijmn&quot;</code></li></ul><p>See also: <a href="#OMEinsum.DefaultBackend"><code>DefaultBackend</code></a>, <a href="#OMEinsum.set_einsum_backend!-Tuple{EinsumBackend}"><code>set_einsum_backend!</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/backends.jl#LL55-L108">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.DefaultBackend"><a class="docstring-binding" href="#OMEinsum.DefaultBackend"><code>OMEinsum.DefaultBackend</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">DefaultBackend &lt;: EinsumBackend</code></pre><p>Default backend using BLAS/CUBLAS for tensor contractions.</p><p>This backend reduces tensor contractions to matrix multiplications (GEMM) by:</p><ol><li>Analyzing the contraction pattern to identify inner/outer/batch indices</li><li>Permuting tensors to canonical GEMM form if needed</li><li>Reshaping tensors to 2D/3D matrices</li><li>Calling optimized BLAS routines (<code>gemm!</code>, <code>gemm_strided_batched!</code>)</li><li>Reshaping and permuting the result back</li></ol><p><strong>Pros</strong></p><ul><li>Highly optimized for matrix-like contractions</li><li>Works with any array type that supports <code>mul!</code></li><li>No additional library dependencies</li></ul><p><strong>Cons</strong></p><ul><li>Overhead from permute/reshape for non-GEMM patterns</li><li>May allocate intermediate arrays</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">set_einsum_backend!(DefaultBackend())
ein&quot;ij,jk-&gt;ik&quot;(A, B)  # Uses BLAS gemm</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/backends.jl#LL26-L52">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.DynamicEinCode"><a class="docstring-binding" href="#OMEinsum.DynamicEinCode"><code>OMEinsum.DynamicEinCode</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">DynamicEinCode{LT}
DynamicEinCode(ixs, iy)</code></pre><p>Wrapper to <code>eincode</code>-specification that creates a callable object to evaluate the <code>eincode</code> <code>ixs -&gt; iy</code> where <code>ixs</code> are the index-labels of the input-tensors and <code>iy</code> are the index-labels of the output.</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; a, b = rand(2,2), rand(2,2);

julia&gt; OMEinsum.DynamicEinCode(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)),(&#39;i&#39;,&#39;k&#39;))(a, b) ≈ a * b
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL65-L81">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.DynamicNestedEinsum"><a class="docstring-binding" href="#OMEinsum.DynamicNestedEinsum"><code>OMEinsum.DynamicNestedEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">DynamicNestedEinsum{LT} &lt;: NestedEinsum{LT}
DynamicNestedEinsum(args, eins)
DynamicNestedEinsum{LT}(tensorindex::Int)</code></pre><p>Einsum with contraction order, where the type parameter <code>LT</code> is the label type. It has two constructors. One takes a <code>tensorindex</code> as input, which represents the leaf node in a contraction tree. The other takes an iterable of type <code>DynamicNestedEinsum</code>, <code>args</code>, as the siblings, and <code>eins</code> to specify the contraction operation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL163-L171">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.EinArray"><a class="docstring-binding" href="#OMEinsum.EinArray"><code>OMEinsum.EinArray</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">EinArray{T, N, TT, LX, LY, ICT, OCT} &lt;: AbstractArray{T, N}</code></pre><p>A struct to hold the intermediate result of an <code>einsum</code> where all index-labels of both input and output are expanded to a rank-<code>N</code>-array whose values are lazily calculated. Indices are arranged as <em>inner indices</em> (or reduced dimensions) first and <em>then outer indices</em>.</p><p>Type parameters are</p><pre><code class="language-julia hljs">* `T`: element type,
* `N`: array dimension,
* `TT`: type of &quot;tuple of input arrays&quot;,
* `LX`: type of &quot;tuple of input indexers&quot;,
* `LX`: type of output indexer,
* `ICT`: typeof inner CartesianIndices,
* `OCT`: typeof outer CartesianIndices,</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL147-L164">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.EinCode"><a class="docstring-binding" href="#OMEinsum.EinCode"><code>OMEinsum.EinCode</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">EinCode &lt;: AbstractEinsum
EinCode(ixs, iy)</code></pre><p>Abstract type for sum-product contraction code. The constructor returns a <code>DynamicEinCode</code> instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL13-L19">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.EinIndexer"><a class="docstring-binding" href="#OMEinsum.EinIndexer"><code>OMEinsum.EinIndexer</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">EinIndexer{locs,N}</code></pre><p>A structure for indexing <code>EinArray</code>s. <code>locs</code> is the index positions (among all indices). In the constructor, <code>size</code> is the size of target tensor,</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL116-L121">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.EinIndexer-Union{Tuple{NTuple{N, Int64}}, Tuple{locs}, Tuple{N}} where {N, locs}"><a class="docstring-binding" href="#OMEinsum.EinIndexer-Union{Tuple{NTuple{N, Int64}}, Tuple{locs}, Tuple{N}} where {N, locs}"><code>OMEinsum.EinIndexer</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">EinIndexer{locs}(size::Tuple)</code></pre><p>Constructor for <code>EinIndexer</code> for an object of size <code>size</code> where <code>locs</code> are the locations of relevant indices in a larger tuple.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL126-L131">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.EinsumBackend"><a class="docstring-binding" href="#OMEinsum.EinsumBackend"><code>OMEinsum.EinsumBackend</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">EinsumBackend</code></pre><p>Abstract type for einsum computation backends.</p><p>OMEinsum supports multiple backends for tensor contractions, allowing users to choose the most appropriate implementation for their hardware and use case.</p><p><strong>Available Backends</strong></p><ul><li><a href="#OMEinsum.DefaultBackend"><code>DefaultBackend</code></a>: Uses BLAS/CUBLAS with reshape/permute operations</li><li><a href="#OMEinsum.CuTensorBackend"><code>CuTensorBackend</code></a>: Uses NVIDIA cuTENSOR for native tensor contractions</li></ul><p><strong>Usage</strong></p><pre><code class="language-julia hljs"># Check current backend
get_einsum_backend()

# Change backend globally
set_einsum_backend!(CuTensorBackend())</code></pre><p>See also: <a href="#OMEinsum.set_einsum_backend!-Tuple{EinsumBackend}"><code>set_einsum_backend!</code></a>, <a href="#OMEinsum.get_einsum_backend-Tuple{}"><code>get_einsum_backend</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/backends.jl#LL1-L23">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.IndexGroup"><a class="docstring-binding" href="#OMEinsum.IndexGroup"><code>OMEinsum.IndexGroup</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">IndexGroup</code></pre><p>Leaf in a contractiontree, contains the indices and the number of the tensor it describes, e.g. in &quot;ij,jk -&gt; ik&quot;, indices &quot;ik&quot; belong to tensor <code>1</code>, so would be described by IndexGroup([&#39;i&#39;,&#39;k&#39;], 1).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL88-L94">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.NestedEinsum"><a class="docstring-binding" href="#OMEinsum.NestedEinsum"><code>OMEinsum.NestedEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">NestedEinsum{LT} &lt;: AbstractEinsum</code></pre><p>The abstract type for contraction trees. It has two subtypes, <a href="#OMEinsum.DynamicNestedEinsum"><code>DynamicNestedEinsum</code></a> and <a href="#OMEinsum.StaticNestedEinsum"><code>StaticNestedEinsum</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL156-L160">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.NestedEinsumConstructor"><a class="docstring-binding" href="#OMEinsum.NestedEinsumConstructor"><code>OMEinsum.NestedEinsumConstructor</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">NestedEinsumConstructor</code></pre><p>describes a (potentially) nested einsum. Important fields:</p><ul><li><code>args</code>, vector of all inputs, either <code>IndexGroup</code> objects corresponding to tensors or <code>NestedEinsumConstructor</code></li><li><code>iy</code>, indices of output</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL103-L109">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.SlicedEinsum"><a class="docstring-binding" href="#OMEinsum.SlicedEinsum"><code>OMEinsum.SlicedEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">SlicedEinsum{LT, Ein} &lt;: AbstractEinsum</code></pre><p>A tensor network with slicing. <code>LT</code> is the label type and <code>Ein</code> is the tensor network.</p><p><strong>Fields</strong></p><ul><li><code>slicing::Vector{LT}</code>: A vector of labels to slice.</li><li><code>eins::Ein</code>: The tensor network.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/slicing.jl#LL1-L9">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.StaticEinCode"><a class="docstring-binding" href="#OMEinsum.StaticEinCode"><code>OMEinsum.StaticEinCode</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">StaticEinCode{LT, ixs, iy}</code></pre><p>The static version of <code>DynamicEinCode</code> that matches the contraction rule at compile time. It is the default return type of <code>@ein_str</code> macro. <code>LT</code> is the label type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL22-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.StaticNestedEinsum"><a class="docstring-binding" href="#OMEinsum.StaticNestedEinsum"><code>OMEinsum.StaticNestedEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">StaticNestedEinsum{LT,args,eins} &lt;: NestedEinsum{LT}
StaticNestedEinsum(args, eins)
StaticNestedEinsum{LT}(tensorindex::Int)</code></pre><p>Einsum with contraction order, where the type parameter <code>LT</code> is the label type, <code>args</code> is a tuple of StaticNestedEinsum, <code>eins</code> is a <code>StaticEinCode</code> and leaf node is defined by setting <code>eins</code> to an integer. It has two constructors. One takes a <code>tensorindex</code> as input, which represents the leaf node in a contraction tree. The other takes an iterable of type <code>DynamicNestedEinsum</code>, <code>args</code>, as the siblings, and <code>eins</code> to specify the contraction operation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL191-L200">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Base.getindex-Union{Tuple{T}, Tuple{EinArray{T}, Any}} where T"><a class="docstring-binding" href="#Base.getindex-Union{Tuple{T}, Tuple{EinArray{T}, Any}} where T"><code>Base.getindex</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">getindex(A::EinArray, inds...)</code></pre><p>return the lazily calculated entry of <code>A</code> at index <code>inds</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL227-L231">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.allow_loops-Tuple{Bool}"><a class="docstring-binding" href="#OMEinsum.allow_loops-Tuple{Bool}"><code>OMEinsum.allow_loops</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">allow_loops(flag::Bool)</code></pre><p>Setting this to <code>false</code> will cause OMEinsum to log an error if it falls back to <code>loop_einsum</code> evaluation, instead of calling specialised kernels. The default is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/loop_einsum.jl#LL65-L70">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.allunique-Tuple{Any}"><a class="docstring-binding" href="#OMEinsum.allunique-Tuple{Any}"><code>OMEinsum.allunique</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">allunique(ix::Tuple)</code></pre><p>return true if all elements of <code>ix</code> appear only once in <code>ix</code>.</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using OMEinsum: allunique

julia&gt; allunique((1,2,3,4))
true

julia&gt; allunique((1,2,3,1))
false</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/utils.jl#LL87-L103">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.analyze_binary-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}, Vector{T}, Dict{T, Int64}}} where T"><a class="docstring-binding" href="#OMEinsum.analyze_binary-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}, Vector{T}, Dict{T, Int64}}} where T"><code>OMEinsum.analyze_binary</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Get the expected labels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsum.jl#LL136-L138">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.asarray-Tuple{Any}"><a class="docstring-binding" href="#OMEinsum.asarray-Tuple{Any}"><code>OMEinsum.asarray</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">asarray(x[, parent::AbstractArray]) -&gt; AbstactArray</code></pre><p>Return a 0-dimensional array with item <code>x</code>, otherwise, do nothing. If a <code>parent</code> is supplied, it will try to match the parent array type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/utils.jl#LL39-L44">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.back_propagate-Union{Tuple{T}, Tuple{Any, SlicedEinsum, OMEinsum.CacheTree{T}, AbstractArray{T}, Dict}} where T"><a class="docstring-binding" href="#OMEinsum.back_propagate-Union{Tuple{T}, Tuple{Any, SlicedEinsum, OMEinsum.CacheTree{T}, AbstractArray{T}, Dict}} where T"><code>OMEinsum.back_propagate</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">back_propagate(f, code, cache, ȳ, size_dict)</code></pre><p>Back propagate the message <code>ȳ</code> through the cached tree <code>cache</code> and return a tree storing the intermediate messages. The message can be gradients et al.</p><p><strong>Arguments</strong></p><ul><li><code>f</code>: The back-propagation rule. The signature is <code>f(eins, xs, y, size_dict, dy) -&gt; dxs</code>, where<ul><li><code>eins</code>: The contraction code at the current node.</li><li><code>xs</code>: The input tensors at the current node.</li><li><code>y</code>: The output tensor at the current node.</li><li><code>size_dict</code>: The size dictionary, which maps the label to the size of the corresponding dimension.</li><li><code>dy</code>: The message on the output tensor (<code>y</code>) to back-propagate through the current node.</li><li><code>dxs</code>: The message on the input tensors (<code>xs</code>) as the result of back-propagation.</li></ul></li><li><code>code</code>: The contraction code, which can be a <code>NestedEinsum</code> or a <code>SlicedEinsum</code>.</li><li><code>cache</code>: The cached intermediate results, which can be generated by <a href="#OMEinsum.cached_einsum-Tuple{SlicedEinsum, Any, Any}"><code>cached_einsum</code></a>.</li><li><code>ȳ</code>: The message to back-propagate.</li><li><code>size_dict</code>: The size dictionary, which maps the label to the size of the corresponding dimension.</li></ul><p><strong>Returns</strong></p><ul><li><code>CacheTree</code>: The tree storing the intermediate messages.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/bp.jl#LL50-L71">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.cached_einsum-Tuple{SlicedEinsum, Any, Any}"><a class="docstring-binding" href="#OMEinsum.cached_einsum-Tuple{SlicedEinsum, Any, Any}"><code>OMEinsum.cached_einsum</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">cached_einsum(code, xs, size_dict)</code></pre><p>Compute the einsum contraction and cache the intermediate contraction results.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: The contraction code, which can be a <code>NestedEinsum</code> or a <code>SlicedEinsum</code>.</li><li><code>xs</code>: The input tensors.</li><li><code>size_dict</code>: The size dictionary, which maps the label to the size of the corresponding dimension.</li></ul><p><strong>Returns</strong></p><ul><li><code>CacheTree</code>: The cached tree storing the intermediate results.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/bp.jl#LL11-L23">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.cost_and_gradient"><a class="docstring-binding" href="#OMEinsum.cost_and_gradient"><code>OMEinsum.cost_and_gradient</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">cost_and_gradient(code, xs, ȳ)</code></pre><p>Compute the cost and the gradients w.r.t the input tensors <code>xs</code>.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: The contraction code, which can be a <code>NestedEinsum</code> or a <code>SlicedEinsum</code>.</li><li><code>xs</code>: The input tensors.</li><li><code>ȳ</code>: The message to back-propagate. Default is <code>1</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>cost</code>: The cost of the contraction.</li><li><code>grads</code>: The gradients w.r.t the input tensors.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/bp.jl#LL108-L121">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.einarray-Union{Tuple{TT}, Tuple{NI}, Tuple{iy}, Tuple{ixs}, Tuple{Val{ixs}, Val{iy}, TT, Any}} where {ixs, iy, NI, TT&lt;:NTuple{NI, AbstractArray}}"><a class="docstring-binding" href="#OMEinsum.einarray-Union{Tuple{TT}, Tuple{NI}, Tuple{iy}, Tuple{ixs}, Tuple{Val{ixs}, Val{iy}, TT, Any}} where {ixs, iy, NI, TT&lt;:NTuple{NI, AbstractArray}}"><code>OMEinsum.einarray</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">einarray(::Val{ixs}, Val{iy}, xs, size_dict) -&gt; EinArray</code></pre><p>Constructor of <code>EinArray</code> from an <code>EinCode</code>, a tuple of tensors <code>xs</code> and a <code>size_dict</code> that assigns each index-label a size. The returned <code>EinArray</code> holds an intermediate result of the <code>einsum</code> specified by the <code>EinCode</code> with indices corresponding to all unique labels in the einsum. Reduction over the (lazily calculated) dimensions that correspond to labels not present in the output lead to the result of the einsum.</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using OMEinsum: get_size_dict

julia&gt; a, b = rand(2,2), rand(2,2);

julia&gt; sd = get_size_dict(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)), (a, b));

julia&gt; ea = OMEinsum.einarray(Val(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;))),Val((&#39;i&#39;,&#39;k&#39;)), (a,b), sd);

julia&gt; dropdims(sum(ea, dims=1), dims=1) ≈ a * b
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL177-L200">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.einsum"><a class="docstring-binding" href="#OMEinsum.einsum"><code>OMEinsum.einsum</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">einsum(code::EinCode, xs, size_dict)</code></pre><p>Return the tensor that results from contracting the tensors <code>xs</code> according to the contraction code <code>code</code>.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: The einsum notation, which can be an instance of <a href="#OMEinsum.EinCode"><code>EinCode</code></a>, <a href="#OMEinsum.NestedEinsum"><code>NestedEinsum</code></a>, or <a href="#OMEinsum.SlicedEinsum"><code>SlicedEinsum</code></a>.</li><li><code>xs</code> - the input tensors</li><li><code>size_dict</code> - a dictionary that maps index-labels to their sizes</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; a, b = rand(2,2), rand(2,2);

julia&gt; einsum(EinCode(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)),(&#39;i&#39;,&#39;k&#39;)), (a, b)) ≈ a * b
true

julia&gt; einsum(EinCode(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)),(&#39;k&#39;,&#39;i&#39;)), (a, b)) ≈ permutedims(a * b, (2,1))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsum.jl#LL2-L24">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.einsum!"><a class="docstring-binding" href="#OMEinsum.einsum!"><code>OMEinsum.einsum!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">einsum!(code::EinCode, xs, y, sx, sy, size_dict)</code></pre><p>Inplace version of <code>einsum</code>. The result is stored in <code>y</code>.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: The einsum notation, which can be an instance of <a href="#OMEinsum.EinCode"><code>EinCode</code></a>, <a href="#OMEinsum.NestedEinsum"><code>NestedEinsum</code></a>, or <a href="#OMEinsum.SlicedEinsum"><code>SlicedEinsum</code></a>.</li><li><code>xs</code>: The input tensors.</li><li><code>y</code>: The output tensor.</li><li><code>sx</code>: Scale <code>x</code> by <code>sx</code>.</li><li><code>sy</code>: Scale <code>y</code> by <code>sy</code>.</li><li><code>size_dict</code>: A dictionary that maps index-labels to their sizes.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsum.jl#LL30-L42">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.einsum_grad-NTuple{6, Any}"><a class="docstring-binding" href="#OMEinsum.einsum_grad-NTuple{6, Any}"><code>OMEinsum.einsum_grad</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">einsum_grad(ixs, xs, iy, size_dict, cdy, i)</code></pre><p>return the gradient of the result of evaluating the <code>EinCode</code> w.r.t the <code>i</code>th tensor in <code>xs</code>. <code>cdy</code> is the result of applying the <code>EinCode</code> to the <code>xs</code>.</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using OMEinsum: einsum_grad, get_size_dict

julia&gt; a, b = rand(2,2), rand(2,2);

julia&gt; c = einsum(EinCode(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)), (&#39;i&#39;,&#39;k&#39;)), (a,b));

julia&gt; sd = get_size_dict(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)), (a,b));

julia&gt; einsum_grad(((&#39;i&#39;,&#39;j&#39;),(&#39;j&#39;,&#39;k&#39;)), (a,b), (&#39;i&#39;,&#39;k&#39;), sd, c, 1) ≈ c * transpose(b)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/autodiff.jl#LL3-L24">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.filliys!-Tuple{Any}"><a class="docstring-binding" href="#OMEinsum.filliys!-Tuple{Any}"><code>OMEinsum.filliys!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">filliys!(neinsum::NestedEinsumConstructor)</code></pre><p>goes through all <code>NestedEinsumConstructor</code> objects in the tree and saves the correct <code>iy</code> in them.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL67-L71">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.get_einsum_backend-Tuple{}"><a class="docstring-binding" href="#OMEinsum.get_einsum_backend-Tuple{}"><code>OMEinsum.get_einsum_backend</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">get_einsum_backend() -&gt; EinsumBackend</code></pre><p>Get the current global einsum backend.</p><p><strong>Returns</strong></p><p>The currently active <code>EinsumBackend</code> instance.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">backend = get_einsum_backend()
if backend isa CuTensorBackend
    println(&quot;Using cuTENSOR&quot;)
else
    println(&quot;Using default BLAS/CUBLAS&quot;)
end</code></pre><p>See also: <a href="#OMEinsum.set_einsum_backend!-Tuple{EinsumBackend}"><code>set_einsum_backend!</code></a>, <a href="#OMEinsum.EinsumBackend"><code>EinsumBackend</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/backends.jl#LL203-L222">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.get_size_dict!-Union{Tuple{LT}, Tuple{Any, Any, Dict{LT}}} where LT"><a class="docstring-binding" href="#OMEinsum.get_size_dict!-Union{Tuple{LT}, Tuple{Any, Any, Dict{LT}}} where LT"><code>OMEinsum.get_size_dict!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">get_size_dict!(ixs, xs, size_info)</code></pre><p>return a dictionary that is used to get the size of an index-label in the einsum-specification with input-indices <code>ixs</code> and tensors <code>xs</code> after consistency within <code>ixs</code> and between <code>ixs</code> and <code>xs</code> has been verified.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/interfaces.jl#LL60-L67">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.getixsv-Union{Tuple{StaticEinCode{LT}}, Tuple{LT}} where LT"><a class="docstring-binding" href="#OMEinsum.getixsv-Union{Tuple{StaticEinCode{LT}}, Tuple{LT}} where LT"><code>OMEinsum.getixsv</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">getixsv(code)</code></pre><p>Get labels of input tensors for <code>EinCode</code>, <code>NestedEinsum</code> and some other einsum like objects. Returns a vector of vectors.</p><pre><code class="language-julia-repl hljs">julia&gt; getixsv(ein&quot;(ij,jk),k-&gt;i&quot;)
3-element Vector{Vector{Char}}:
 [&#39;i&#39;, &#39;j&#39;]
 [&#39;j&#39;, &#39;k&#39;]
 [&#39;k&#39;]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL33-L46">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.getiyv-Union{Tuple{StaticEinCode{LT}}, Tuple{LT}} where LT"><a class="docstring-binding" href="#OMEinsum.getiyv-Union{Tuple{StaticEinCode{LT}}, Tuple{LT}} where LT"><code>OMEinsum.getiyv</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">getiy(code)</code></pre><p>Get labels of the output tensor for <code>EinCode</code>, <code>NestedEinsum</code> and some other einsum like objects. Returns a vector.</p><pre><code class="language-julia-repl hljs">julia&gt; getiyv(ein&quot;(ij,jk),k-&gt;i&quot;)
1-element Vector{Char}:
 &#39;i&#39;: ASCII/Unicode U+0069 (category Ll: Letter, lowercase)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL48-L59">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.indices_and_locs-Tuple{Any, Any}"><a class="docstring-binding" href="#OMEinsum.indices_and_locs-Tuple{Any, Any}"><code>OMEinsum.indices_and_locs</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">indices_and_locs(ixs,iy)</code></pre><p>given the index-labels of input and output of an <code>einsum</code>, return (in the same order):</p><ul><li>a tuple of the distinct index-labels of the output <code>iy</code></li><li>a tuple of the distinct index-labels in <code>ixs</code> of the input not appearing in the output <code>iy</code></li><li>a tuple of tuples of locations of an index-label in the <code>ixs</code> in a list of all index-labels</li><li>a tuple of locations of index-labels in <code>iy</code> in a list of all index-labels</li></ul><p>where the list of all index-labels is simply the first  and the second output catenated and the second output catenated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL245-L256">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.loop_einsum!-Union{Tuple{T}, Tuple{L}, Tuple{N}, Tuple{Any, Any, NTuple{N, AbstractArray}, AbstractArray{T, L}, Any, Any, Any}} where {N, L, T}"><a class="docstring-binding" href="#OMEinsum.loop_einsum!-Union{Tuple{T}, Tuple{L}, Tuple{N}, Tuple{Any, Any, NTuple{N, AbstractArray}, AbstractArray{T, L}, Any, Any, Any}} where {N, L, T}"><code>OMEinsum.loop_einsum!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">loop_einsum!(ixs, iy, xs, y, sx, sy, size_dict)</code></pre><p>inplace-version of <code>loop_einsum</code>, saving the result in a preallocated tensor of correct size <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/loop_einsum.jl#LL15-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.loop_einsum-Union{Tuple{N}, Tuple{EinCode, NTuple{N, AbstractArray}, Any}} where N"><a class="docstring-binding" href="#OMEinsum.loop_einsum-Union{Tuple{N}, Tuple{EinCode, NTuple{N, AbstractArray}, Any}} where N"><code>OMEinsum.loop_einsum</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">loop_einsum(::EinCode, xs, size_dict)</code></pre><p>evaluates the eincode specified by <code>EinCode</code> and the tensors <code>xs</code> by looping over all possible indices and calculating the contributions ot the result. Scales exponentially in the number of distinct index-labels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/loop_einsum.jl#LL1-L7">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.map_prod-Union{Tuple{N}, Tuple{Tuple, Any, NTuple{N, Any}}} where N"><a class="docstring-binding" href="#OMEinsum.map_prod-Union{Tuple{N}, Tuple{Tuple, Any, NTuple{N, Any}}} where N"><code>OMEinsum.map_prod</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">map_prod(xs, ind, indexers)</code></pre><p>calculate the value of an <code>EinArray</code> with <code>EinIndexer</code>s <code>indexers</code> at location <code>ind</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/Core.jl#LL235-L240">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.match_rule-Tuple{Any, Any}"><a class="docstring-binding" href="#OMEinsum.match_rule-Tuple{Any, Any}"><code>OMEinsum.match_rule</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">match_rule(ixs, iy)
match_rule(code::EinCode)</code></pre><p>Returns the rule that matches, otherwise use <code>DefaultRule</code> - the slow <code>loop_einsum</code> backend.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/matchrule.jl#LL1-L7">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.nopermute-Tuple{NTuple{N, T} where {N, T}, NTuple{N, T} where {N, T}}"><a class="docstring-binding" href="#OMEinsum.nopermute-Tuple{NTuple{N, T} where {N, T}, NTuple{N, T} where {N, T}}"><code>OMEinsum.nopermute</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">nopermute(ix,iy)</code></pre><p>check that all values in <code>iy</code> that are also in <code>ix</code> have the same relative order,</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using OMEinsum: nopermute

julia&gt; nopermute((1,2,3),(1,2))
true

julia&gt; nopermute((1,2,3),(2,1))
false</code></pre><p>e.g. <code>nopermute((1,2,3),(1,2))</code> is true while <code>nopermute((1,2,3),(2,1))</code> is false</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/utils.jl#LL58-L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.parse_parens-Tuple{AbstractString, Any, Any}"><a class="docstring-binding" href="#OMEinsum.parse_parens-Tuple{AbstractString, Any, Any}"><code>OMEinsum.parse_parens</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">parse_parens(s::AbstractString, i, narg)</code></pre><p>parse one level of parens starting at index <code>i</code> where <code>narg</code> counts which tensor the current group of indices, e.g. &quot;ijk&quot;, belongs to. Recursively calls itself for each new opening paren that&#39;s opened.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/einsequence.jl#LL19-L25">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.set_einsum_backend!-Tuple{EinsumBackend}"><a class="docstring-binding" href="#OMEinsum.set_einsum_backend!-Tuple{EinsumBackend}"><code>OMEinsum.set_einsum_backend!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">set_einsum_backend!(backend::EinsumBackend) -&gt; EinsumBackend</code></pre><p>Set the global backend for einsum operations.</p><div class="admonition is-info" id="Note-2a0b88d3253cf833"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-2a0b88d3253cf833" title="Permalink"></a></header><div class="admonition-body"><p>This sets a global state. For thread-safe usage in concurrent code, consider using the same backend throughout or synchronizing access.</p></div></div><p><strong>Arguments</strong></p><ul><li><code>backend::EinsumBackend</code>: The backend to use.<ul><li><code>DefaultBackend()</code>: Use BLAS/CUBLAS (default)</li><li><code>CuTensorBackend()</code>: Use cuTENSOR for GPU contractions</li></ul></li></ul><p><strong>Returns</strong></p><p>The backend that was set.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">using OMEinsum, CUDA

# Check current backend
get_einsum_backend()  # DefaultBackend()

# Switch to cuTENSOR
set_einsum_backend!(CuTensorBackend())

# Perform contractions with cuTENSOR
A = CUDA.rand(Float32, 100, 200)
B = CUDA.rand(Float32, 200, 300)
C = ein&quot;ij,jk-&gt;ik&quot;(A, B)

# Reset to default
set_einsum_backend!(DefaultBackend())</code></pre><p><strong>Performance Comparison</strong></p><pre><code class="language-julia hljs">using BenchmarkTools

A = CUDA.rand(Float32, 64, 64, 64)
B = CUDA.rand(Float32, 64, 64, 64)

# DefaultBackend: requires permute + reshape + GEMM + reshape
set_einsum_backend!(DefaultBackend())
@btime CUDA.@sync ein&quot;ijk,jkl-&gt;il&quot;($A, $B)

# CuTensorBackend: direct tensor contraction
set_einsum_backend!(CuTensorBackend())
@btime CUDA.@sync ein&quot;ijk,jkl-&gt;il&quot;($A, $B)</code></pre><p>See also: <a href="#OMEinsum.get_einsum_backend-Tuple{}"><code>get_einsum_backend</code></a>, <a href="#OMEinsum.EinsumBackend"><code>EinsumBackend</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/backends.jl#LL114-L167">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.tensorpermute!-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractArray{T, N}, Any, Any, Any}} where {T, N}"><a class="docstring-binding" href="#OMEinsum.tensorpermute!-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractArray{T, N}, Any, Any, Any}} where {T, N}"><code>OMEinsum.tensorpermute!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">tensorpermute(A, perm)</code></pre><p><code>permutedims(A, perm)</code> with grouped dimensions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/utils.jl#LL117-L121">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.@ein!-Tuple"><a class="docstring-binding" href="#OMEinsum.@ein!-Tuple"><code>OMEinsum.@ein!</code></a> — <span class="docstring-category">Macro</span></summary><section><div><pre><code class="language-julia hljs">@ein! A[i,k] := B[i,j] * C[j,k]     # A = B * C
@ein! A[i,k] += B[i,j] * C[j,k]     # A += B * C
@ein! A[i,k] -= B[i,j] * C[j,k]     # A -= B * C</code></pre><p>Macro interface similar to that of other packages.</p><p>Inplace version of <code>@ein</code>. </p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; a, b, c, d = rand(2,2), rand(2,2), rand(2,2), zeros(2,2);

julia&gt; cc = copy(c);

julia&gt; @ein! d[i,k] := a[i,j] * b[j,k];

julia&gt; d ≈ a * b
true

julia&gt; d ≈ ein&quot;ij,jk -&gt; ik&quot;(a,b)
true

julia&gt; @ein! c[i,k] += a[i,j] * b[j,k];

julia&gt; c ≈ cc + a * b
true

julia&gt; @ein! c[i,k] -= a[i,j] * b[j,k];

julia&gt; c ≈ cc
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/interfaces.jl#LL176-L210">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.@ein-Tuple"><a class="docstring-binding" href="#OMEinsum.@ein-Tuple"><code>OMEinsum.@ein</code></a> — <span class="docstring-category">Macro</span></summary><section><div><pre><code class="language-julia hljs">@ein A[i,k] := B[i,j] * C[j,k]     # A = B * C</code></pre><p>Macro interface similar to that of other packages.</p><p>You may use numbers in place of letters for dummy indices, as in <code>@tensor</code>, and need not name the output array. Thus <code>A = @ein [1,2] := B[1,ξ] * C[ξ,2]</code> is equivalent to the above. This can also be written <code>A = ein&quot;ij,jk -&gt; ik&quot;(B,C)</code> using the numpy-style string macro.</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; a, b = rand(2,2), rand(2,2);

julia&gt; @ein c[i,k] := a[i,j] * b[j,k];

julia&gt; c ≈ a * b
true

julia&gt; c ≈ ein&quot;ij,jk -&gt; ik&quot;(a,b)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/interfaces.jl#LL117-L140">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.@ein_str-Tuple{AbstractString}"><a class="docstring-binding" href="#OMEinsum.@ein_str-Tuple{AbstractString}"><code>OMEinsum.@ein_str</code></a> — <span class="docstring-category">Macro</span></summary><section><div><pre><code class="language-julia hljs">ein&quot;ij,jk -&gt; ik&quot;(A,B)</code></pre><p>String macro interface which understands <code>numpy.einsum</code>&#39;s notation. Translates strings into <code>StaticEinCode</code>-structs that can be called to evaluate an <code>einsum</code>. To control evaluation order, use parentheses - instead of an <code>EinCode</code>, a <code>NestedEinsum</code> is returned which evaluates the expression according to parens. The valid character ranges for index-labels are <code>a-z</code> and <code>α-ω</code>.</p><p><strong>example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; a, b, c = rand(10,10), rand(10,10), rand(10,1);

julia&gt; ein&quot;ij,jk,kl -&gt; il&quot;(a,b,c) ≈ ein&quot;(ij,jk),kl -&gt; il&quot;(a,b,c) ≈ a * b * c
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/interfaces.jl#LL1-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsum.@optein_str-Tuple{AbstractString}"><a class="docstring-binding" href="#OMEinsum.@optein_str-Tuple{AbstractString}"><code>OMEinsum.@optein_str</code></a> — <span class="docstring-category">Macro</span></summary><section><div><pre><code class="language-julia hljs">optein&quot;ij,jk,kl -&gt; ik&quot;(A, B, C)</code></pre><p>String macro interface that similar to <a href="#OMEinsum.@ein_str-Tuple{AbstractString}"><code>@ein_str</code></a>, with optimized contraction order (dimensions are assumed to be uniform).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/under-Peter/OMEinsum.jl/blob/1afc9843cbf988e48a6fe149822aa30295a989d9/src/interfaces.jl#LL25-L29">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.AbstractDecompositionType"><a class="docstring-binding" href="#OMEinsumContractionOrders.AbstractDecompositionType"><code>OMEinsumContractionOrders.AbstractDecompositionType</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">AbstractDecompositionType</code></pre><p>Abstract type for decomposition types, which includes <a href="#OMEinsumContractionOrders.TreeDecomp"><code>TreeDecomp</code></a> and <a href="#OMEinsumContractionOrders.PathDecomp"><code>PathDecomp</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L91-L95">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.AbstractEinsum"><a class="docstring-binding" href="#OMEinsumContractionOrders.AbstractEinsum"><code>OMEinsumContractionOrders.AbstractEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">AbstractEinsum</code></pre><p>Abstract type for einsum notations.</p><p><strong>Required Interfaces</strong></p><ul><li><code>getixsv</code>: a vector of vectors, each vector represents the labels associated with a input tensor.</li><li><code>getiyv</code>: a vector of labels associated with the output tensor.</li><li><code>uniquelabels</code>: a vector of labels that are unique in the einsum notation.</li></ul><p><strong>Derived interfaces</strong></p><ul><li><code>labeltype</code>: the data type to represent the labels in the einsum notation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L2-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.BipartiteResult"><a class="docstring-binding" href="#OMEinsumContractionOrders.BipartiteResult"><code>OMEinsumContractionOrders.BipartiteResult</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">BipartiteResult{RT}
BipartiteResult(part1, part2, sc, valid)</code></pre><p>Result of the bipartite optimization. <code>part1</code> and <code>part2</code> are the two parts of the bipartition, <code>sc</code> is the space complexity of the bipartition, <code>valid</code> is a boolean indicating whether the bipartition is valid.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/kahypar.jl#L39-L44">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.CodeOptimizer"><a class="docstring-binding" href="#OMEinsumContractionOrders.CodeOptimizer"><code>OMEinsumContractionOrders.CodeOptimizer</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CodeOptimizer</code></pre><p>Abstract type for code optimizers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L77-L81">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.CodeSimplifier"><a class="docstring-binding" href="#OMEinsumContractionOrders.CodeSimplifier"><code>OMEinsumContractionOrders.CodeSimplifier</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CodeSimplifier</code></pre><p>Abstract type for code simplifiers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/simplify.jl#L3-L7">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.CodeSlicer"><a class="docstring-binding" href="#OMEinsumContractionOrders.CodeSlicer"><code>OMEinsumContractionOrders.CodeSlicer</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CodeSlicer</code></pre><p>Abstract type for code slicers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L84-L88">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.EinCode"><a class="docstring-binding" href="#OMEinsumContractionOrders.EinCode"><code>OMEinsumContractionOrders.EinCode</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">EinCode{LT} &lt;: AbstractEinsum
EinCode(ixs::Vector{Vector{LT}}, iy::Vector{LT})</code></pre><p>Einsum code with input indices <code>ixs</code> and output index <code>iy</code>.</p><p><strong>Examples</strong></p><p>The einsum notation for matrix multiplication is:</p><pre><code class="language-julia-repl hljs">julia&gt; code = OMEinsumContractionOrders.EinCode([[1,2], [2, 3]], [1, 3])
1∘2, 2∘3 -&gt; 1∘3

julia&gt; OMEinsumContractionOrders.getixsv(code)
2-element Vector{Vector{Int64}}:
 [1, 2]
 [2, 3]

julia&gt; OMEinsumContractionOrders.getiyv(code)
2-element Vector{Int64}:
 1
 3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L46-L68">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.ExactTreewidth"><a class="docstring-binding" href="#OMEinsumContractionOrders.ExactTreewidth"><code>OMEinsumContractionOrders.ExactTreewidth</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">const ExactTreewidth = Treewidth{SafeRules{BT, MMW{3}(), MF}}
ExactTreewidth() = Treewidth()</code></pre><p><code>ExactTreewidth</code> is a specialization of <code>Treewidth</code> for the <code>SafeRules</code> preprocessing algorithm with the <code>BT</code> elimination algorithm. The <code>BT</code> algorithm is an exact solver for the treewidth problem that implemented in <a href="https://github.com/ArrogantGao/TreeWidthSolver.jl"><code>TreeWidthSolver.jl</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treewidth.jl#L50-L56">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.GreedyMethod"><a class="docstring-binding" href="#OMEinsumContractionOrders.GreedyMethod"><code>OMEinsumContractionOrders.GreedyMethod</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">GreedyMethod{MT}
GreedyMethod(; α = 0.0, temperature = 0.0)</code></pre><p>It may not be optimal, but it is fast.</p><p><strong>Fields</strong></p><ul><li><code>α</code> is the parameter for the loss function, for pairwise interaction, L = size(out) - α * (size(in1) + size(in2))</li><li><code>temperature</code> is the parameter for sampling, if it is zero, the minimum loss is selected; for non-zero, the loss is selected by the Boltzmann distribution, given by p ~ exp(-loss/temperature).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/greedy.jl#L336-L345">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.HyperND"><a class="docstring-binding" href="#OMEinsumContractionOrders.HyperND"><code>OMEinsumContractionOrders.HyperND</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">HyperND(;
    dis = KaHyParND(),
    algs = (MF(), AMF(), MMD()),
    level = 6,
    width = 120,
    scale = 100,
    imbalances = 130:130,
    score = ScoreFunction(),
)</code></pre><p>Nested-dissection based optimizer. Recursively partitions a tensor network, then calls a greedy algorithm on the leaves. The optimizer is run a number of times: once for each greedy algorithm in <code>algs</code> and each imbalance value in <code>imbalances</code>. The recursion depth is controlled by the parameters <code>level</code> and <code>width</code>. The parameter <code>scale</code> controls discretization of the index weights:</p><pre><code class="language-julia hljs">weight(i) := scale * log2(dim(i))</code></pre><p>where dim(i) is the dimension of the index i.</p><p>The line graph is partitioned using the algorithm <code>dis</code>. OMEinsumContractionOrders currently supports two partitioning algorithms, both of which require importing an external library.</p><table><tr><th style="text-align: left">type</th><th style="text-align: left">package</th></tr><tr><td style="text-align: left"><a href="https://algebraicjulia.github.io/CliqueTrees.jl/stable/api/#CliqueTrees.METISND"><code>METISND</code></a></td><td style="text-align: left"><a href="https://github.com/JuliaSparse/Metis.jl">Metis.jl</a></td></tr><tr><td style="text-align: left"><a href="https://algebraicjulia.github.io/CliqueTrees.jl/stable/api/#CliqueTrees.KaHyParND"><code>KaHyParND</code></a></td><td style="text-align: left"><a href="https://github.com/kahypar/KaHyPar.jl">KayHyPar.jl</a></td></tr></table><p>The optimizer is implemented using the tree decomposition library <a href="https://github.com/AlgebraicJulia/CliqueTrees.jl">CliqueTrees.jl</a>.</p><p><strong>Arguments</strong></p><ul><li><code>dis</code>: <a href="https://algebraicjulia.github.io/CliqueTrees.jl/stable/api/#CliqueTrees.DissectionAlgorithm">graph partitioning algorithm</a></li><li><code>algs</code>: tuple of <a href="https://algebraicjulia.github.io/CliqueTrees.jl/stable/api/#Elimination-Algorithms">elimination algorithms</a>.</li><li><code>level</code>: maximum level</li><li><code>width</code>: minimum width</li><li><code>imbalances</code>: imbalance parameters </li><li><code>score</code>: a function to evaluate the quality of the contraction tree. Default is <code>ScoreFunction()</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/hypernd.jl#L1-L40">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.KaHyParBipartite"><a class="docstring-binding" href="#OMEinsumContractionOrders.KaHyParBipartite"><code>OMEinsumContractionOrders.KaHyParBipartite</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">KaHyParBipartite{RT,IT,GM}
KaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),
    max_group_size=40, greedy_config=GreedyMethod())</code></pre><p>Optimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are</p><p><strong>Fields</strong></p><ul><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>imbalances</code> is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>sub_optimizer</code> is the sub-optimizer used to find the contraction order when the group size is small enough.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li><li><a href="https://arxiv.org/abs/2103.03074">Simulating the Sycamore quantum supremacy circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/kahypar.jl#L1-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.MergeGreedy"><a class="docstring-binding" href="#OMEinsumContractionOrders.MergeGreedy"><code>OMEinsumContractionOrders.MergeGreedy</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">MergeGreedy &lt;: CodeSimplifier
MergeGreedy(; threshhold=-1e-12)</code></pre><p>Contraction code simplifier (in order to reduce the time of calling optimizers) that merges tensors greedily if the space complexity of merged tensors is reduced (difference smaller than the <code>threshhold</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/simplify.jl#L10-L16">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.MergeVectors"><a class="docstring-binding" href="#OMEinsumContractionOrders.MergeVectors"><code>OMEinsumContractionOrders.MergeVectors</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">MergeVectors &lt;: CodeSimplifier
MergeVectors()</code></pre><p>Contraction code simplifier (in order to reduce the time of calling optimizers) that merges vectors to closest tensors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/simplify.jl#L21-L26">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.NestedEinsum"><a class="docstring-binding" href="#OMEinsumContractionOrders.NestedEinsum"><code>OMEinsumContractionOrders.NestedEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">NestedEinsum{LT} &lt;: AbstractEinsum
NestedEinsum(args::Vector{NestedEinsum}, eins::EinCode)</code></pre><p>The einsum notation with a contraction order specified as a tree data structure. It is automatically generated by the contraction code optimizer with the <a href="#OMEinsumContractionOrders.optimize_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Dict, CodeOptimizer}"><code>optimize_code</code></a> function.</p><p><strong>Fields</strong></p><ul><li><code>args</code>: the children of the current node</li><li><code>tensorindex</code>: the index of the input tensor, required only for leaf nodes. For non-leaf nodes, it is <code>-1</code>.</li><li><code>eins</code>: the einsum notation for the operation at the current node.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L145-L156">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.NetworkSimplifier"><a class="docstring-binding" href="#OMEinsumContractionOrders.NetworkSimplifier"><code>OMEinsumContractionOrders.NetworkSimplifier</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">NetworkSimplifier{LT}</code></pre><p>A network simplifier that contains a list of operations that can be applied to a tensor network to reduce the number of tensors. It is generated from a proprocessor, such as <a href="#OMEinsumContractionOrders.MergeVectors"><code>MergeVectors</code></a> or <a href="#OMEinsumContractionOrders.MergeGreedy"><code>MergeGreedy</code></a>.</p><p><strong>Fields</strong></p><ul><li><code>operations</code>: a list of <code>NestedEinsum</code> objects.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/simplify.jl#L29-L37">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.PathDecomp"><a class="docstring-binding" href="#OMEinsumContractionOrders.PathDecomp"><code>OMEinsumContractionOrders.PathDecomp</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PathDecomp &lt;: AbstractDecompositionType</code></pre><p>Path decomposition type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L105-L109">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.PathSA-Tuple{}"><a class="docstring-binding" href="#OMEinsumContractionOrders.PathSA-Tuple{}"><code>OMEinsumContractionOrders.PathSA</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">PathSA(; βs=0.01:0.05:15, ntrials=10, niters=50, score=ScoreFunction())</code></pre><p>Optimize the einsum contraction pattern using the simulated annealing on tensor expression tree, with path decomposition.</p><p><strong>Fields</strong></p><ul><li><code>βs</code>, <code>ntrials</code>, <code>niters</code> and <code>score</code> are the same as in <a href="#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treesa.jl#L139-L146">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.SABipartite"><a class="docstring-binding" href="#OMEinsumContractionOrders.SABipartite"><code>OMEinsumContractionOrders.SABipartite</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">SABipartite{RT,BT}
SABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000
    max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)</code></pre><p>Optimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are</p><p><strong>Fields</strong></p><ul><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>ntrials</code> is the number of repetition (with different random seeds),</li><li><code>βs</code> is a list of inverse temperature <code>1/T</code>,</li><li><code>niters</code> is the number of iteration in each temperature,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>sub_optimizer</code> is the optimizer for the bipartited sub graphs, one can choose <code>GreedyMethod()</code> or <code>TreeSA()</code>,</li><li><code>initializer</code> is the partition configuration initializer, one can choose <code>:random</code> or <code>:greedy</code> (slow but better).</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/sabipartite.jl#L1-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.ScoreFunction"><a class="docstring-binding" href="#OMEinsumContractionOrders.ScoreFunction"><code>OMEinsumContractionOrders.ScoreFunction</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ScoreFunction</code></pre><p>A function to compute the score of a contraction code:</p><pre><code class="language-julia hljs">score = tc_weight * 2^tc + rw_weight * 2^rw + sc_weight * max(0, 2^sc - 2^sc_target)</code></pre><p><strong>Fields</strong></p><ul><li><code>tc_weight</code>: the weight of the time complexity, default is 1.0.</li><li><code>sc_weight</code>: the weight of the space complexity (the size of the largest tensor), default is 1.0.</li><li><code>rw_weight</code>: the weight of the read-write complexity, default is 0.0.</li><li><code>sc_target</code>: the target space complexity, below which the <code>sc_weight</code> will be set to 0 automatically, default is 0.0.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L112-L126">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.SlicedEinsum"><a class="docstring-binding" href="#OMEinsumContractionOrders.SlicedEinsum"><code>OMEinsumContractionOrders.SlicedEinsum</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">SlicedEinsum{LT,ET&lt;:Union{EinCode{LT},NestedEinsum{LT}}} &lt;: AbstractEinsum
SlicedEinsum(slicing::Vector{LT}, eins::ET)</code></pre><p>The einsum notation with sliced indices. The sliced indices are the indices enumerated manually at the top level. By slicing the indices, the space complexity of the einsum notation can be reduced.</p><p><strong>Fields</strong></p><ul><li><code>slicing</code>: the sliced indices.</li><li><code>eins</code>: the einsum notation of the current node, which is a <a href="#OMEinsumContractionOrders.NestedEinsum"><code>NestedEinsum</code></a> object.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L197-L207">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.TreeDecomp"><a class="docstring-binding" href="#OMEinsumContractionOrders.TreeDecomp"><code>OMEinsumContractionOrders.TreeDecomp</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TreeDecomp &lt;: AbstractDecompositionType</code></pre><p>Tree decomposition type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L98-L102">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.TreeSA"><a class="docstring-binding" href="#OMEinsumContractionOrders.TreeSA"><code>OMEinsumContractionOrders.TreeSA</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TreeSA{IT, DT} &lt;: CodeOptimizer
TreeSA(; βs=collect(0.01:0.05:15), ntrials=10, niters=50, initializer=:greedy, score=ScoreFunction(), decomposition_type=TreeDeomp())</code></pre><p>Optimize the einsum contraction pattern using the simulated annealing on tensor expression tree.</p><p><strong>Fields</strong></p><ul><li><code>ntrials</code>, <code>βs</code> and <code>niters</code> are annealing parameters, doing <code>ntrials</code> indepedent annealings, each has inverse tempteratures specified by <code>βs</code>, in each temperature, do <code>niters</code> updates of the tree.</li><li><code>initializer</code> specifies how to determine the initial configuration, it can be <code>:greedy</code>, <code>:random</code> or <code>:specified</code>. If the initializer is <code>:specified</code>, the input <code>code</code> should be a <code>NestedEinsum</code> object.</li><li><code>score</code> specifies the score function to evaluate the quality of the contraction tree, it is a function of time complexity, space complexity and read-write complexity.</li><li><code>decomposition_type</code> specifies the type of decomposition to use, it can be <code>TreeDeomp</code> or <code>PathDecomp</code>.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2108.05665">Recursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits</a></li></ul><p><strong>Breaking changes:</strong></p><ul><li><code>nslices</code> is removed, since the slicing part is now separated from the optimization part, see <code>slice_code</code> function and <code>TreeSASlicer</code>.</li><li><code>greedy_method</code> is removed. If you want to have detailed control of the initializer, please pre-optimize the code with another method and then use <code>:specified</code> to initialize the tree.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treesa.jl#L110-L128">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.TreeSASlicer"><a class="docstring-binding" href="#OMEinsumContractionOrders.TreeSASlicer"><code>OMEinsumContractionOrders.TreeSASlicer</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TreeSASlicer{IT, LT} &lt;: CodeSlicer</code></pre><p>A structure for configuring the Tree Simulated Annealing (TreeSA) slicing algorithm. The goal of slicing is to reach the target space complexity specified by <code>score.sc_target</code>.</p><p><strong>Fields</strong></p><ul><li><code>ntrials</code>, <code>βs</code> and <code>niters</code> are annealing parameters, doing <code>ntrials</code> indepedent annealings, each has inverse tempteratures specified by <code>βs</code>, in each temperature, do <code>niters</code> updates of the tree.</li><li><code>fixed_slices::Vector{LT}</code>: A vector of fixed slices that should not be altered. Default is an empty vector.</li><li><code>optimization_ratio::Float64</code>: A constant used for determining the number of iterations for slicing. Default is 2.0. i.e. if the current space complexity is 30, and the target space complexity is 20, then the number of iterations for slicing is (30 - 20) x <code>optimization_ratio</code>.</li><li><code>score::ScoreFunction</code>: A function to evaluate the quality of the contraction tree. Default is <code>ScoreFunction(sc_target=30.0)</code>.</li><li><code>decomposition_type::AbstractDecompositionType</code>: The type of decomposition to use. Default is <code>TreeDecomp()</code>.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2108.05665">Recursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treesaslicer.jl#L48-L63">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.Treewidth"><a class="docstring-binding" href="#OMEinsumContractionOrders.Treewidth"><code>OMEinsumContractionOrders.Treewidth</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct Treewidth{EL &lt;: EliminationAlgorithm, GM} &lt;: CodeOptimizer
Treewidth(; alg::EL = SafeRules(BT(), MMW{3}(), MF()))</code></pre><p>Tree width based solver. The solvers are implemented in <a href="https://algebraicjulia.github.io/CliqueTrees.jl/stable/">CliqueTrees.jl</a> and <a href="https://github.com/ArrogantGao/TreeWidthSolver.jl">TreeWidthSolver.jl</a>. They include:</p><table><tr><th style="text-align: left">Algorithm</th><th style="text-align: left">Description</th><th style="text-align: left">Time Complexity</th><th style="text-align: left">Space Complexity</th></tr><tr><td style="text-align: left"><code>AMF</code></td><td style="text-align: left">approximate minimum fill</td><td style="text-align: left">O(mn)</td><td style="text-align: left">O(m + n)</td></tr><tr><td style="text-align: left"><code>MF</code></td><td style="text-align: left">minimum fill</td><td style="text-align: left">O(mn²)</td><td style="text-align: left">-</td></tr><tr><td style="text-align: left"><code>MMD</code></td><td style="text-align: left">multiple minimum degree</td><td style="text-align: left">O(mn²)</td><td style="text-align: left">O(m + n)</td></tr></table><p>Detailed descriptions is available in the <a href="https://algebraicjulia.github.io/CliqueTrees.jl/stable/api/#Elimination-Algorithms">CliqueTrees.jl</a>.</p><p><strong>Fields</strong></p><ul><li><code>alg::EL</code>: The algorithm to use for the treewidth calculation. Available elimination algorithms are listed above.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; optimizer = Treewidth();

julia&gt; eincode = OMEinsumContractionOrders.EinCode([[&#39;a&#39;, &#39;b&#39;], [&#39;a&#39;, &#39;c&#39;, &#39;d&#39;], [&#39;b&#39;, &#39;c&#39;, &#39;e&#39;, &#39;f&#39;], [&#39;e&#39;], [&#39;d&#39;, &#39;f&#39;]], [&#39;a&#39;])
ab, acd, bcef, e, df -&gt; a

julia&gt; size_dict = Dict([c=&gt;(1&lt;&lt;i) for (i,c) in enumerate([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;])]...)
Dict{Char, Int64} with 6 entries:
  &#39;f&#39; =&gt; 64
  &#39;a&#39; =&gt; 2
  &#39;c&#39; =&gt; 8
  &#39;d&#39; =&gt; 16
  &#39;e&#39; =&gt; 32
  &#39;b&#39; =&gt; 4

julia&gt; optcode = optimize_code(eincode, size_dict, optimizer)
ab, ba -&gt; a
├─ ab
└─ bcf, acf -&gt; ba
   ├─ bcef, e -&gt; bcf
   │  ├─ bcef
   │  └─ e
   └─ acd, df -&gt; acf
      ├─ acd
      └─ df</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treewidth.jl#L1-L45">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.compute_contraction_dims-NTuple{6, Any}"><a class="docstring-binding" href="#OMEinsumContractionOrders.compute_contraction_dims-NTuple{6, Any}"><code>OMEinsumContractionOrders.compute_contraction_dims</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">compute_contraction_dims(incidence_list, log2_edge_sizes, vi, vj, eout, eremove) -&gt; (D1, D2, D12, D01, D02, D012)</code></pre><p>Compute the log2 dimensions and edge lists for contracting vertices <code>vi</code> and <code>vj</code>. Returns a tuple of six Float64 dimension values:</p><ul><li>D1: edges only in vi and internal</li><li>D2: edges only in vj and internal</li><li>D12: edges in both vi and vj and internal</li><li>D01: edges only in vi and external</li><li>D02: edges only in vj and external</li><li>D012: edges in both vi and vj and external</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/greedy.jl#L130-L141">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.contraction_complexity-Tuple{OMEinsumContractionOrders.AbstractEinsum, Any}"><a class="docstring-binding" href="#OMEinsumContractionOrders.contraction_complexity-Tuple{OMEinsumContractionOrders.AbstractEinsum, Any}"><code>OMEinsumContractionOrders.contraction_complexity</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">contraction_complexity(eincode, size_dict) -&gt; ContractionComplexity</code></pre><p>Returns the time, space and read-write complexity of the einsum contraction. The returned <code>ContractionComplexity</code> object contains 3 fields:</p><ul><li><code>tc</code>: time complexity defined as <code>log2(number of element-wise multiplications)</code>.</li><li><code>sc</code>: space complexity defined as <code>log2(size of the maximum intermediate tensor)</code>.</li><li><code>rwc</code>: read-write complexity defined as <code>log2(the number of read-write operations)</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/complexity.jl#L200-L208">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.convert_label-Union{Tuple{T2}, Tuple{T1}, Tuple{OMEinsumContractionOrders.NestedEinsum, Dict{T1, T2}}} where {T1, T2}"><a class="docstring-binding" href="#OMEinsumContractionOrders.convert_label-Union{Tuple{T2}, Tuple{T1}, Tuple{OMEinsumContractionOrders.NestedEinsum, Dict{T1, T2}}} where {T1, T2}"><code>OMEinsumContractionOrders.convert_label</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">convert_label(ne::NestedEinsum, labelmap::Dict{T1,T2}) where {T1,T2}</code></pre><p>Convert the labels of a <code>NestedEinsum</code> object to new labels. <code>labelmap</code> is a dictionary that maps the old labels to the new labels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/utils.jl#L14-L19">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.einexpr_to_matrix!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, AbstractVector{&lt;:AbstractVector{L}}, AbstractVector{L}, AbstractDict{L}}} where L"><a class="docstring-binding" href="#OMEinsumContractionOrders.einexpr_to_matrix!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, AbstractVector{&lt;:AbstractVector{L}}, AbstractVector{L}, AbstractDict{L}}} where L"><code>OMEinsumContractionOrders.einexpr_to_matrix!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">einexpr_to_matrix!(marker, ixs, iy, size_dict)</code></pre><p>Construct the weighted incidence matrix correponding to an Einstein summation expression. Returns a quadruple (weights, ev, ve, el).</p><p>Each Einstein summation expression has a set E ⊆ L of indices, a set V := {1, …, |V|} of (inner) tensors, and an outer tensor * := |V| + 1. Each tensor v ∈ V is incident to a sequence ixs[v] of indices, and the outer tensor is incident to the sequence iy. Note that an index can appear multiple times in ixs[v], e.g.</p><pre><code class="language-julia hljs">ixs[v] = (&#39;a&#39;, &#39;a&#39;, &#39;b&#39;).</code></pre><p>Each index l ∈ E also has a positive dimension, given by size_dict[l].</p><p>The function <code>einexpr_to_matrix</code> does two things. First of all, it enumerates the index set E, mapping each index to a distinct natural number.</p><pre><code class="language-julia hljs">el: {1, …, |E|} → E
le: E → {1, …, |E|}</code></pre><p>Next, it constructs a vector weights: {1, …, |E|} → [0, ∞) satisfying</p><pre><code class="language-julia hljs">weights[e] := log2(size_dict[el[e]]),</code></pre><p>and a sparse matrix ve: {1, …, |V| + 1} × {1, …, |E|} → {0, 1} satisfying</p><pre><code class="language-julia hljs">ve[v, e] := { 1 if el[e] is incident to v
            { 0 otherwise</code></pre><p>We can think of the pair H := (weights, ve) as an edge-weighted hypergraph with incidence matrix ve.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treewidth.jl#L96-L128">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.embed_simplifier-Tuple{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.NetworkSimplifier}"><a class="docstring-binding" href="#OMEinsumContractionOrders.embed_simplifier-Tuple{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.NetworkSimplifier}"><code>OMEinsumContractionOrders.embed_simplifier</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">embed_simplifier(code::NestedEinsum, simplifier::NetworkSimplifier)</code></pre><p>Embed the simplifier into the contraction code. A typical workflow is: (i) generate a simplifier with <a href="#OMEinsumContractionOrders.simplify_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Any, MergeVectors}"><code>simplify_code</code></a>, (ii) then optimize the simplified code with <a href="#OMEinsumContractionOrders.optimize_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Dict, CodeOptimizer}"><code>optimize_code</code></a> and (iii) post-process the optimized code with <a href="#OMEinsumContractionOrders.embed_simplifier-Tuple{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.NetworkSimplifier}"><code>embed_simplifier</code></a> to produce correct contraction order for the original code. This is automatically done in <a href="#OMEinsumContractionOrders.optimize_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Dict, CodeOptimizer}"><code>optimize_code</code></a> given the <code>simplifier</code> argument is not <code>nothing</code>.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: the contraction code to embed the simplifier into.</li><li><code>simplifier</code>: the simplifier to embed, which is a <a href="#OMEinsumContractionOrders.NetworkSimplifier"><code>NetworkSimplifier</code></a> object.</li></ul><p><strong>Returns</strong></p><ul><li>A new <code>NestedEinsum</code> object.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/simplify.jl#L117-L131">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.flop-Union{Tuple{VT}, Tuple{LT}, Tuple{OMEinsumContractionOrders.EinCode, Dict{LT, VT}}} where {LT, VT}"><a class="docstring-binding" href="#OMEinsumContractionOrders.flop-Union{Tuple{VT}, Tuple{LT}, Tuple{OMEinsumContractionOrders.EinCode, Dict{LT, VT}}} where {LT, VT}"><code>OMEinsumContractionOrders.flop</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">flop(eincode, size_dict) -&gt; Int</code></pre><p>Returns the number of iterations, which is different with the true floating point operations (FLOP) by a factor of 2.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/complexity.jl#L124-L128">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.getixsv"><a class="docstring-binding" href="#OMEinsumContractionOrders.getixsv"><code>OMEinsumContractionOrders.getixsv</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">getixsv(code::AbstractEinsum) -&gt; Vector{Vector{LT}}</code></pre><p>Returns the input indices of the einsum notation. Each vector represents the labels associated with a input tensor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L17-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.getiyv"><a class="docstring-binding" href="#OMEinsumContractionOrders.getiyv"><code>OMEinsumContractionOrders.getiyv</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">getiyv(code::AbstractEinsum) -&gt; Vector{LT}</code></pre><p>Returns the output index of the einsum notation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L25-L29">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.label_elimination_order-Tuple{OMEinsumContractionOrders.NestedEinsum}"><a class="docstring-binding" href="#OMEinsumContractionOrders.label_elimination_order-Tuple{OMEinsumContractionOrders.NestedEinsum}"><code>OMEinsumContractionOrders.label_elimination_order</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">label_elimination_order(code) -&gt; Vector</code></pre><p>Returns a vector of labels sorted by the order they are eliminated in the contraction tree. The contraction tree is specified by <code>code</code>, which e.g. can be a <code>NestedEinsum</code> instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/complexity.jl#L168-L173">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.labeltype-Tuple{OMEinsumContractionOrders.AbstractEinsum}"><a class="docstring-binding" href="#OMEinsumContractionOrders.labeltype-Tuple{OMEinsumContractionOrders.AbstractEinsum}"><code>OMEinsumContractionOrders.labeltype</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">labeltype(code::AbstractEinsum) -&gt; Type</code></pre><p>Returns the data type to represent the labels in the einsum notation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L39-L43">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.matrix_to_tree!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, AbstractVector{Float64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, AbstractVector{L}, CliqueTrees.EliminationAlgorithm}} where L"><a class="docstring-binding" href="#OMEinsumContractionOrders.matrix_to_tree!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, AbstractVector{Float64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, AbstractVector{L}, CliqueTrees.EliminationAlgorithm}} where L"><code>OMEinsumContractionOrders.matrix_to_tree!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">matrix_to_tree!(marker, weights, ev, ve, el, alg)</code></pre><p>Construct a tree decomposition of an edge-weighted hypergraph using the elimination algorithm <code>alg</code>. We ensure that the indices incident to the outer tensor are contained in the root bag of the tree decomposition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treewidth.jl#L208-L214">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.optimize_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Dict, CodeOptimizer}"><a class="docstring-binding" href="#OMEinsumContractionOrders.optimize_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Dict, CodeOptimizer}"><code>OMEinsumContractionOrders.optimize_code</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">optimize_code(eincode, size_dict, optimizer = GreedyMethod(); slicer=nothing, simplifier=nothing, permute=true) -&gt; optimized_eincode</code></pre><p>Optimize the einsum contraction code and reduce the time/space complexity of tensor network contraction. Returns a <code>NestedEinsum</code> instance. Input arguments are</p><p><strong>Arguments</strong></p><ul><li><code>eincode</code> is an einsum contraction code instance, one of <code>DynamicEinCode</code>, <code>StaticEinCode</code> or <code>NestedEinsum</code>.</li><li><code>size</code> is a dictionary of &quot;edge label=&gt;edge size&quot; that contains the size information, one can use <code>uniformsize(eincode, 2)</code> to create a uniform size.</li><li><code>optimizer</code> is a <code>CodeOptimizer</code> instance, should be one of <code>GreedyMethod</code>, <code>Treewidth</code>, <code>KaHyParBipartite</code>, <code>SABipartite</code> or <code>TreeSA</code>. Check their docstrings for details.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>slicer</code> is for slicing the contraction code to reduce the space complexity, default is nothing. Currently only <a href="#OMEinsumContractionOrders.TreeSASlicer"><code>TreeSASlicer</code></a> is supported.</li><li><code>simplifier</code> is one of <code>MergeVectors</code> or <code>MergeGreedy</code>. Default is nothing.</li><li><code>permute</code> is a boolean flag to indicate whether to optimize the permutation of the contraction order.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using OMEinsum

julia&gt; code = ein&quot;ij, jk, kl, il-&gt;&quot;
ij, jk, kl, il -&gt; 

julia&gt; optimize_code(code, uniformsize(code, 2), TreeSA());</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/interfaces.jl#L1-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.optimize_greedy-Union{Tuple{T2}, Tuple{L}, Tuple{OMEinsumContractionOrders.AbstractEinsum, Dict{L, T2}}} where {L, T2}"><a class="docstring-binding" href="#OMEinsumContractionOrders.optimize_greedy-Union{Tuple{T2}, Tuple{L}, Tuple{OMEinsumContractionOrders.AbstractEinsum, Dict{L, T2}}} where {L, T2}"><code>OMEinsumContractionOrders.optimize_greedy</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">optimize_greedy(eincode, size_dict; α, temperature)</code></pre><p>Greedy optimizing the contraction order and return a <code>NestedEinsum</code> object. Check the docstring of <code>tree_greedy</code> for detailed explaination of other input arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/greedy.jl#L252-L257">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.optimize_sa-Tuple{OMEinsumContractionOrders.EinCode, Any}"><a class="docstring-binding" href="#OMEinsumContractionOrders.optimize_sa-Tuple{OMEinsumContractionOrders.EinCode, Any}"><code>OMEinsumContractionOrders.optimize_sa</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">optimize_sa(code, size_dict; sc_target, max_group_size=40, βs=0.1:0.2:15.0, niters=1000, ntrials=50,
       sub_optimizer = GreedyMethod(), initializer=:random)</code></pre><p>Optimize the einsum <code>code</code> contraction order using the Simulated Annealing bipartition + Greedy approach. <code>size_dict</code> is a dictionary that specifies leg dimensions.  Check the docstring of <code>SABipartite</code> for detailed explaination of other input arguments.</p><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/sabipartite.jl#L202-L212">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.optimize_tree-Union{Tuple{LT}, Tuple{OMEinsumContractionOrders.AbstractEinsum, Dict{LT, Int64}}} where LT"><a class="docstring-binding" href="#OMEinsumContractionOrders.optimize_tree-Union{Tuple{LT}, Tuple{OMEinsumContractionOrders.AbstractEinsum, Dict{LT, Int64}}} where LT"><code>OMEinsumContractionOrders.optimize_tree</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">optimize_tree(code, size_dict; βs, ntrials, niters, initializer, score)</code></pre><p>Optimize the einsum contraction pattern specified by <code>code</code>, and edge sizes specified by <code>size_dict</code>. Check the docstring of <a href="#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a> for detailed explaination of other input arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treesa.jl#L152-L157">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.optimize_treewidth-Tuple{OMEinsumContractionOrders.Treewidth, OMEinsumContractionOrders.AbstractEinsum, Dict}"><a class="docstring-binding" href="#OMEinsumContractionOrders.optimize_treewidth-Tuple{OMEinsumContractionOrders.Treewidth, OMEinsumContractionOrders.AbstractEinsum, Dict}"><code>OMEinsumContractionOrders.optimize_treewidth</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">optimize_treewidth(optimizer, eincode, size_dict)</code></pre><p>Optimizing the contraction order via solve the exact tree width of the line graph corresponding to the eincode and return a <code>NestedEinsum</code> object. Check the docstring of <code>treewidth_method</code> for detailed explaination of other input arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treewidth.jl#L60-L65">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.peak_memory-Tuple{OMEinsumContractionOrders.NestedEinsum, Dict}"><a class="docstring-binding" href="#OMEinsumContractionOrders.peak_memory-Tuple{OMEinsumContractionOrders.NestedEinsum, Dict}"><code>OMEinsumContractionOrders.peak_memory</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">peak_memory(code, size_dict::Dict) -&gt; Int</code></pre><p>Estimate peak memory in number of elements.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/complexity.jl#L2-L6">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.readjson-Tuple{AbstractString}"><a class="docstring-binding" href="#OMEinsumContractionOrders.readjson-Tuple{AbstractString}"><code>OMEinsumContractionOrders.readjson</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">readjson(filename::AbstractString)</code></pre><p>Read the contraction order from a JSON file.</p><p><strong>Arguments</strong></p><ul><li><code>filename</code>: the name of the file to read from.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/json.jl#L29-L36">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.simplify_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Any, MergeVectors}"><a class="docstring-binding" href="#OMEinsumContractionOrders.simplify_code-Tuple{Union{OMEinsumContractionOrders.EinCode, OMEinsumContractionOrders.NestedEinsum}, Any, MergeVectors}"><code>OMEinsumContractionOrders.simplify_code</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">simplify_code(code::Union{EinCode, NestedEinsum}, size_dict, method::CodeSimplifier)</code></pre><p>Simplify the contraction code by preprocessing the code with a simplifier.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: the contraction code to simplify.</li><li><code>size_dict</code>: the size dictionary of the contraction code.</li><li><code>method</code>: the simplifier to use, which can be <a href="#OMEinsumContractionOrders.MergeVectors"><code>MergeVectors</code></a> or <a href="#OMEinsumContractionOrders.MergeGreedy"><code>MergeGreedy</code></a>.</li></ul><p><strong>Returns</strong></p><ul><li>A tuple of <code>(NetworkSimplifier, newcode)</code>, where <code>newcode</code> is a new <code>EinCode</code> object.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/simplify.jl#L42-L54">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.slice_code-Tuple{OMEinsumContractionOrders.NestedEinsum, Any, TreeSASlicer}"><a class="docstring-binding" href="#OMEinsumContractionOrders.slice_code-Tuple{OMEinsumContractionOrders.NestedEinsum, Any, TreeSASlicer}"><code>OMEinsumContractionOrders.slice_code</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">slice_code(code, size_dict, slicer) -&gt; sliced_code</code></pre><p>Slice the einsum contraction code to reduce the space complexity, returns a <code>SlicedEinsum</code> instance.</p><p><strong>Arguments</strong></p><ul><li><code>code</code> is a <code>NestedEinsum</code> instance.</li><li><code>size_dict</code> is a dictionary of &quot;edge label=&gt;edge size&quot; that contains the size information, one can use <code>uniformsize(eincode, 2)</code> to create a uniform size.</li><li><code>slicer</code> is a <code>CodeSlicer</code> instance, currently only <a href="#OMEinsumContractionOrders.TreeSASlicer"><code>TreeSASlicer</code></a> is supported.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/interfaces.jl#L66-L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.tree_greedy-Union{Tuple{ET}, Tuple{TT}, Tuple{TA}, Tuple{OMEinsumContractionOrders.IncidenceList{Int64, ET}, Any}} where {TA, TT, ET}"><a class="docstring-binding" href="#OMEinsumContractionOrders.tree_greedy-Union{Tuple{ET}, Tuple{TT}, Tuple{TA}, Tuple{OMEinsumContractionOrders.IncidenceList{Int64, ET}, Any}} where {TA, TT, ET}"><code>OMEinsumContractionOrders.tree_greedy</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">tree_greedy(incidence_list, log2_sizes; α = 0.0, temperature = 0.0)</code></pre><p>Compute greedy order, and the time and space complexities, the rows of the <code>incidence_list</code> are vertices and columns are edges. <code>log2_sizes</code> are defined on edges. <code>α</code> is the parameter for the loss function, for pairwise interaction, L = size(out) - α * (size(in1) + size(in2)) <code>temperature</code> is the parameter for sampling, if it is zero, the minimum loss is selected; for non-zero, the loss is selected by the Boltzmann distribution, given by p ~ exp(-loss/temperature).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/greedy.jl#L16-L23">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.tree_to_einexpr!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, CliqueTrees.CliqueTree{Int64, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, AbstractVector{L}, AbstractVector{&lt;:AbstractVector{L}}, AbstractVector{L}}} where L"><a class="docstring-binding" href="#OMEinsumContractionOrders.tree_to_einexpr!-Union{Tuple{L}, Tuple{AbstractVector{Int64}, CliqueTrees.CliqueTree{Int64, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}, AbstractVector{L}, AbstractVector{&lt;:AbstractVector{L}}, AbstractVector{L}}} where L"><code>OMEinsumContractionOrders.tree_to_einexpr!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">tree_to_einexpr!(marker, tree, ve, el, ixs, iy)</code></pre><p>Transform a tree decomposition into a contraction tree.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/treewidth.jl#L261-L265">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.uniformsize-Tuple{OMEinsumContractionOrders.AbstractEinsum, Any}"><a class="docstring-binding" href="#OMEinsumContractionOrders.uniformsize-Tuple{OMEinsumContractionOrders.AbstractEinsum, Any}"><code>OMEinsumContractionOrders.uniformsize</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">uniformsize(code::AbstractEinsum, size::Int) -&gt; Dict</code></pre><p>Returns a dictionary that maps each label to the given size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/complexity.jl#L161-L165">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.uniquelabels-Tuple{OMEinsumContractionOrders.AbstractEinsum}"><a class="docstring-binding" href="#OMEinsumContractionOrders.uniquelabels-Tuple{OMEinsumContractionOrders.AbstractEinsum}"><code>OMEinsumContractionOrders.uniquelabels</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">uniquelabels(code::AbstractEinsum) -&gt; Vector{LT}</code></pre><p>Returns the unique labels in the einsum notation. The labels are the indices of the tensors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/Core.jl#L32-L36">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.viz_contraction-Tuple"><a class="docstring-binding" href="#OMEinsumContractionOrders.viz_contraction-Tuple"><code>OMEinsumContractionOrders.viz_contraction</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">viz_contraction(code::Union{NestedEinsum, SlicedEinsum}; locs=StressLayout(), framerate=10, filename=tempname() * &quot;.mp4&quot;, show_progress=true)</code></pre><p>Visualize the contraction process of a tensor network.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: The tensor network to visualize.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>locs</code>: The coordinates or layout algorithm to use for positioning the nodes in the graph. Default is <code>StressLayout()</code>.</li><li><code>framerate</code>: The frame rate of the animation. Default is <code>10</code>.</li><li><code>filename</code>: The name of the output file, with <code>.gif</code> or <code>.mp4</code> extension. Default is a temporary file with <code>.mp4</code> extension.</li><li><code>show_progress</code>: Whether to show progress information. Default is <code>true</code>.</li></ul><p><strong>Returns</strong></p><ul><li>the path of the generated file.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/visualization.jl#L27-L43">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.viz_eins-Tuple"><a class="docstring-binding" href="#OMEinsumContractionOrders.viz_eins-Tuple"><code>OMEinsumContractionOrders.viz_eins</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">viz_eins(code::AbstractEinsum; locs=StressLayout(), filename = nothing, kwargs...)</code></pre><p>Visualizes an <code>AbstractEinsum</code> object by creating a tensor network graph and rendering it using GraphViz.</p><p><strong>Arguments</strong></p><ul><li><code>code::AbstractEinsum</code>: The <code>AbstractEinsum</code> object to visualize.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>locs=StressLayout()</code>: The coordinates or layout algorithm to use for positioning the nodes in the graph.</li><li><code>filename = nothing</code>: The name of the file to save the visualization to. If <code>nothing</code>, the visualization will be displayed on the screen instead of saving to a file.</li><li><code>config = GraphDisplayConfig()</code>: The configuration for displaying the graph. Please refer to the documentation of <a href="https://giggleliu.github.io/LuxorGraphPlot.jl/dev/ref/#LuxorGraphPlot.GraphDisplayConfig"><code>GraphDisplayConfig</code></a> for more information.</li><li><code>kwargs...</code>: Additional keyword arguments to be passed to the <a href="https://giggleliu.github.io/LuxorGraphPlot.jl/dev/ref/#LuxorGraphPlot.GraphViz"><code>GraphViz</code></a> constructor.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/visualization.jl#L9-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="OMEinsumContractionOrders.writejson-Tuple{AbstractString, Union{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.SlicedEinsum}}"><a class="docstring-binding" href="#OMEinsumContractionOrders.writejson-Tuple{AbstractString, Union{OMEinsumContractionOrders.NestedEinsum, OMEinsumContractionOrders.SlicedEinsum}}"><code>OMEinsumContractionOrders.writejson</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">writejson(filename::AbstractString, ne::Union{NestedEinsum, SlicedEinsum})</code></pre><p>Write the contraction order to a JSON file.</p><p><strong>Arguments</strong></p><ul><li><code>filename</code>: the name of the file to write to.</li><li><code>ne</code>: the contraction order to write. It can be a <a href="#OMEinsumContractionOrders.NestedEinsum"><code>NestedEinsum</code></a> or a <a href="#OMEinsumContractionOrders.SlicedEinsum"><code>SlicedEinsum</code></a> object.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v1.2.3/src/json.jl#L2-L10">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../applications/">« Applications</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 26 December 2025 09:11">Friday 26 December 2025</span>. Using Julia version 1.12.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
